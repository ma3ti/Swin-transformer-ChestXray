[2026-01-19 10:09:25 swin_tiny_patch4_window7_224] (main.py 364): INFO Full config saved to output/swin_tiny_patch4_window7_224/default/config.json
[2026-01-19 10:09:25 swin_tiny_patch4_window7_224] (main.py 367): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: custom
  DATA_PATH: /content/dataset/chest_xray_new
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_patch4_window7_224
  NUM_CLASSES: 2
  PRETRAINED: /content/swin_tiny_patch4_window7_224.pth
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 3
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_patch4_window7_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 1.25e-08
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 3.125e-08
  WEIGHT_DECAY: 1.0e-08

[2026-01-19 10:09:25 swin_tiny_patch4_window7_224] (main.py 368): INFO {"cfg": "configs/swin/chest_xray_finetune.yaml", "opts": ["MODEL.NUM_CLASSES", "2"], "batch_size": 32, "data_path": "/content/dataset/chest_xray_new", "zip": false, "cache_mode": "part", "pretrained": "/content/swin_tiny_patch4_window7_224.pth", "resume": null, "accumulation_steps": 1, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2026-01-19 10:09:25 swin_tiny_patch4_window7_224] (main.py 94): INFO Creating model:swin/swin_tiny_patch4_window7_224
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (main.py 96): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(7, 7), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(7, 7), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=192
        (reduction): Linear(in_features=768, out_features=384, bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=384, input_resolution=(14, 14), depth=6
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(7, 7), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=384
        (reduction): Linear(in_features=1536, out_features=768, bias=False)
        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=768, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(7, 7), num_heads=24
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=768, out_features=2, bias=True)
)
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (main.py 99): INFO number of params: 27520892
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (main.py 102): INFO number of GFLOPs: 4.493638656
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (main.py 126): INFO USING WEIGHTED LOSS: [Normal: 3.0, Pneumonia: 1.0]
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (main.py 140): INFO no checkpoint found in output/swin_tiny_patch4_window7_224/default, ignoring auto resume
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (utils.py 46): INFO ==============> Loading weight /content/swin_tiny_patch4_window7_224.pth for fine-tuning......
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (utils.py 125): WARNING Error in loading classifier head, re-init classifier head to 0
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (utils.py 128): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index', 'head.weight', 'head.bias'], unexpected_keys=[])
[2026-01-19 10:09:26 swin_tiny_patch4_window7_224] (utils.py 130): INFO => loaded successfully '/content/swin_tiny_patch4_window7_224.pth'
[2026-01-19 10:09:37 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 10.975 (10.975)	Loss 0.6934 (0.6934)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 618MB
[2026-01-19 10:09:38 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.067 (1.147)	Loss 0.6934 (0.6934)	Acc@1 0.000 (44.886)	Acc@5 0.000 (0.000)	Mem 618MB
[2026-01-19 10:09:39 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 27.009 Acc@5 0.000
[2026-01-19 10:09:39 swin_tiny_patch4_window7_224] (main.py 152): INFO Accuracy of the network on the 585 test images: 27.0%
[2026-01-19 10:09:39 swin_tiny_patch4_window7_224] (main.py 158): INFO Start training
[2026-01-19 10:09:46 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][0/146]	eta 0:16:50 lr 0.000000	 wd 0.0000	time 6.9180 (6.9180)	loss 0.9577 (0.9577)	grad_norm 2.9312 (2.9312)	loss_scale 65536.0000 (65536.0000)	mem 2459MB
[2026-01-19 10:09:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][10/146]	eta 0:02:18 lr 0.000000	 wd 0.0000	time 0.4348 (1.0170)	loss 0.9965 (1.0818)	grad_norm 2.3073 (2.7954)	loss_scale 65536.0000 (65536.0000)	mem 2679MB
[2026-01-19 10:09:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][20/146]	eta 0:01:33 lr 0.000000	 wd 0.0000	time 0.3770 (0.7409)	loss 1.0353 (1.1098)	grad_norm 1.5754 (3.1107)	loss_scale 65536.0000 (65536.0000)	mem 2679MB
[2026-01-19 10:10:02 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][30/146]	eta 0:01:24 lr 0.000000	 wd 0.0000	time 0.3320 (0.7269)	loss 1.1522 (1.0971)	grad_norm 4.5194 (3.1082)	loss_scale 65536.0000 (65536.0000)	mem 2679MB
[2026-01-19 10:10:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][40/146]	eta 0:01:10 lr 0.000000	 wd 0.0000	time 0.5656 (0.6631)	loss 1.0353 (1.0925)	grad_norm 1.7648 (3.1517)	loss_scale 65536.0000 (65536.0000)	mem 2679MB
[2026-01-19 10:10:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][50/146]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 0.3983 (0.6788)	loss 1.1132 (1.0996)	grad_norm 2.6650 (3.2103)	loss_scale 65536.0000 (65536.0000)	mem 2679MB
[2026-01-19 10:10:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][60/146]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 0.4900 (0.6437)	loss 1.0742 (1.1018)	grad_norm 2.4798 (inf)	loss_scale 32768.0000 (61238.5574)	mem 2679MB
[2026-01-19 10:10:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][70/146]	eta 0:00:49 lr 0.000000	 wd 0.0000	time 0.4110 (0.6506)	loss 1.1907 (1.1056)	grad_norm 4.5640 (inf)	loss_scale 32768.0000 (57228.6197)	mem 2679MB
[2026-01-19 10:10:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][80/146]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 0.4722 (0.6294)	loss 1.2679 (1.1017)	grad_norm 7.1248 (inf)	loss_scale 32768.0000 (54208.7901)	mem 2679MB
[2026-01-19 10:10:35 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][90/146]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.6119 (0.6161)	loss 1.0351 (1.0961)	grad_norm 2.1372 (inf)	loss_scale 32768.0000 (51852.6593)	mem 2679MB
[2026-01-19 10:10:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][100/146]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.4475 (0.6142)	loss 1.1124 (1.1008)	grad_norm 3.4693 (inf)	loss_scale 32768.0000 (49963.0891)	mem 2679MB
[2026-01-19 10:10:46 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.4644 (0.5996)	loss 1.1122 (1.0990)	grad_norm 3.1848 (inf)	loss_scale 32768.0000 (48413.9820)	mem 2679MB
[2026-01-19 10:10:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.3441 (0.6016)	loss 1.1500 (1.0989)	grad_norm 5.0005 (inf)	loss_scale 32768.0000 (47120.9256)	mem 2679MB
[2026-01-19 10:10:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.3800 (0.5956)	loss 0.9579 (1.1002)	grad_norm 2.4582 (inf)	loss_scale 32768.0000 (46025.2824)	mem 2679MB
[2026-01-19 10:11:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [0/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2126 (0.5737)	loss 0.9969 (1.1004)	grad_norm 2.6014 (inf)	loss_scale 32768.0000 (45085.0496)	mem 2679MB
[2026-01-19 10:11:01 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 0 training takes 0:01:22
[2026-01-19 10:11:10 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.628 (8.628)	Loss 0.6821 (0.6821)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:11:13 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.071 (1.051)	Loss 0.7017 (0.6930)	Acc@1 0.000 (44.886)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:11:14 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 27.179 Acc@5 0.000
[2026-01-19 10:11:14 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 27.2%
[2026-01-19 10:11:14 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_0.pth saving......
[2026-01-19 10:11:18 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_0.pth saved !!!
[2026-01-19 10:11:18 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 0): 27.18% ***
[2026-01-19 10:11:18 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 27.18%
[2026-01-19 10:11:22 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][0/146]	eta 0:11:00 lr 0.000001	 wd 0.0000	time 4.5218 (4.5218)	loss 1.1115 (1.1115)	grad_norm 2.9372 (2.9372)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:11:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][10/146]	eta 0:02:19 lr 0.000001	 wd 0.0000	time 0.5309 (1.0267)	loss 0.9966 (1.0937)	grad_norm 2.2468 (3.4873)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:11:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][20/146]	eta 0:01:34 lr 0.000001	 wd 0.0000	time 0.3263 (0.7498)	loss 0.9593 (1.0765)	grad_norm 3.5332 (3.3431)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:11:38 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][30/146]	eta 0:01:17 lr 0.000001	 wd 0.0000	time 0.3469 (0.6701)	loss 1.2214 (1.1006)	grad_norm 8.1037 (3.9953)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:11:47 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][40/146]	eta 0:01:15 lr 0.000001	 wd 0.0000	time 1.6318 (0.7097)	loss 1.1072 (1.0980)	grad_norm 5.0855 (4.2017)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:11:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][50/146]	eta 0:01:05 lr 0.000001	 wd 0.0000	time 0.5786 (0.6796)	loss 1.1460 (1.1074)	grad_norm 4.8219 (4.4289)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:11:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][60/146]	eta 0:00:56 lr 0.000001	 wd 0.0000	time 0.2624 (0.6578)	loss 1.0320 (1.0995)	grad_norm 3.0559 (4.3386)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][70/146]	eta 0:00:48 lr 0.000001	 wd 0.0000	time 0.4249 (0.6383)	loss 1.0717 (1.0932)	grad_norm 2.1925 (4.2211)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][80/146]	eta 0:00:41 lr 0.000001	 wd 0.0000	time 0.4301 (0.6322)	loss 1.0687 (1.0943)	grad_norm 3.2220 (4.3665)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][90/146]	eta 0:00:34 lr 0.000001	 wd 0.0000	time 0.3938 (0.6134)	loss 1.3227 (1.0958)	grad_norm 12.4553 (4.4908)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:20 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][100/146]	eta 0:00:28 lr 0.000001	 wd 0.0000	time 0.5964 (0.6125)	loss 1.1420 (1.1002)	grad_norm 4.7115 (4.6945)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.3197 (0.6096)	loss 0.9891 (1.0992)	grad_norm 4.2428 (4.8036)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.4208 (0.5969)	loss 0.9873 (1.0972)	grad_norm 4.6159 (4.8033)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:36 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.3457 (0.5968)	loss 0.9928 (1.0944)	grad_norm 2.9584 (4.8839)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:39 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [1/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2014 (0.5764)	loss 1.1656 (1.0925)	grad_norm 8.2610 (4.9071)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:12:40 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 1 training takes 0:01:22
[2026-01-19 10:12:49 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.863 (8.863)	Loss 0.6094 (0.6094)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:12:52 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.067 (1.118)	Loss 0.7202 (0.6755)	Acc@1 3.125 (46.307)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:12:53 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 29.744 Acc@5 0.000
[2026-01-19 10:12:53 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 29.7%
[2026-01-19 10:12:53 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_1.pth saving......
[2026-01-19 10:12:56 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_1.pth saved !!!
[2026-01-19 10:12:56 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 1): 29.74% ***
[2026-01-19 10:12:56 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 29.74%
[2026-01-19 10:13:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][0/146]	eta 0:10:39 lr 0.000001	 wd 0.0000	time 4.3790 (4.3790)	loss 1.0631 (1.0631)	grad_norm 3.7857 (3.7857)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][10/146]	eta 0:02:13 lr 0.000001	 wd 0.0000	time 0.9678 (0.9835)	loss 1.1297 (1.0567)	grad_norm 7.0765 (6.2409)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:12 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][20/146]	eta 0:01:38 lr 0.000001	 wd 0.0000	time 0.7003 (0.7833)	loss 1.0243 (1.0699)	grad_norm 3.2212 (6.2177)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][30/146]	eta 0:01:21 lr 0.000001	 wd 0.0000	time 0.4062 (0.7059)	loss 1.2380 (1.0811)	grad_norm 16.1229 (6.5719)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:22 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][40/146]	eta 0:01:07 lr 0.000001	 wd 0.0000	time 0.4139 (0.6411)	loss 1.1305 (1.0739)	grad_norm 4.6268 (6.7847)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:28 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][50/146]	eta 0:01:00 lr 0.000001	 wd 0.0000	time 0.6932 (0.6351)	loss 1.0233 (1.0675)	grad_norm 3.5884 (6.6251)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][60/146]	eta 0:00:53 lr 0.000002	 wd 0.0000	time 0.3936 (0.6178)	loss 1.0415 (1.0679)	grad_norm 6.4508 (6.7681)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:38 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][70/146]	eta 0:00:44 lr 0.000002	 wd 0.0000	time 0.4409 (0.5905)	loss 1.1666 (1.0689)	grad_norm 10.6698 (6.9853)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:44 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.3732 (0.5976)	loss 1.0234 (1.0695)	grad_norm 3.6395 (7.0535)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:49 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][90/146]	eta 0:00:32 lr 0.000002	 wd 0.0000	time 0.3942 (0.5858)	loss 0.9625 (1.0674)	grad_norm 5.9652 (7.1683)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][100/146]	eta 0:00:26 lr 0.000002	 wd 0.0000	time 0.6500 (0.5831)	loss 1.1193 (1.0662)	grad_norm 9.7454 (7.2986)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:13:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.3257 (0.5716)	loss 1.0792 (1.0642)	grad_norm 8.3173 (7.2854)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][120/146]	eta 0:00:14 lr 0.000002	 wd 0.0000	time 1.6194 (0.5745)	loss 1.1368 (1.0658)	grad_norm 9.4216 (7.3544)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4701 (0.5728)	loss 0.9061 (1.0622)	grad_norm 7.1429 (7.4466)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:15 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [2/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2101 (0.5577)	loss 0.9186 (1.0597)	grad_norm 5.3199 (7.4885)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:16 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 2 training takes 0:01:19
[2026-01-19 10:14:25 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.016 (9.016)	Loss 0.4268 (0.4268)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:14:28 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.077 (1.127)	Loss 0.6909 (0.6131)	Acc@1 75.000 (72.443)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:14:29 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 67.179 Acc@5 0.000
[2026-01-19 10:14:29 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 67.2%
[2026-01-19 10:14:29 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_2.pth saving......
[2026-01-19 10:14:32 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_2.pth saved !!!
[2026-01-19 10:14:32 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 2): 67.18% ***
[2026-01-19 10:14:32 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 67.18%
[2026-01-19 10:14:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][0/146]	eta 0:12:16 lr 0.000002	 wd 0.0000	time 5.0412 (5.0412)	loss 1.0320 (1.0320)	grad_norm 4.8266 (4.8266)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][10/146]	eta 0:02:01 lr 0.000002	 wd 0.0000	time 0.4251 (0.8934)	loss 1.0492 (1.0449)	grad_norm 6.6185 (9.0956)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][20/146]	eta 0:01:36 lr 0.000002	 wd 0.0000	time 0.2784 (0.7675)	loss 0.9475 (1.0104)	grad_norm 7.4086 (8.9534)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:14:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][30/146]	eta 0:01:17 lr 0.000002	 wd 0.0000	time 0.4690 (0.6706)	loss 1.0289 (1.0167)	grad_norm 11.6644 (9.4870)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:15:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][40/146]	eta 0:01:12 lr 0.000002	 wd 0.0000	time 0.8576 (0.6867)	loss 1.0408 (1.0186)	grad_norm 5.6094 (9.1266)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:15:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][50/146]	eta 0:01:02 lr 0.000002	 wd 0.0000	time 0.3892 (0.6472)	loss 0.9401 (1.0167)	grad_norm 6.2459 (8.7933)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:15:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][60/146]	eta 0:00:52 lr 0.000002	 wd 0.0000	time 0.3758 (0.6119)	loss 0.9418 (1.0077)	grad_norm 7.4264 (8.6829)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:15:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.4135 (0.6142)	loss 0.9628 (1.0070)	grad_norm 5.9390 (8.9300)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:15:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.9491 (0.5947)	loss 0.9142 (1.0027)	grad_norm 11.3848 (9.0624)	loss_scale 32768.0000 (32768.0000)	mem 2679MB
[2026-01-19 10:15:26 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.4114 (0.5943)	loss 1.0093 (0.9978)	grad_norm 9.0081 (inf)	loss_scale 16384.0000 (31147.6044)	mem 2679MB
[2026-01-19 10:15:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.3788 (0.5899)	loss 1.0964 (0.9984)	grad_norm 9.0142 (inf)	loss_scale 16384.0000 (29685.8614)	mem 2679MB
[2026-01-19 10:15:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.7280 (0.5812)	loss 0.8819 (0.9952)	grad_norm 7.3817 (inf)	loss_scale 16384.0000 (28487.4955)	mem 2679MB
[2026-01-19 10:15:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][120/146]	eta 0:00:14 lr 0.000002	 wd 0.0000	time 0.6486 (0.5766)	loss 0.9429 (0.9922)	grad_norm 5.8737 (inf)	loss_scale 16384.0000 (27487.2066)	mem 2679MB
[2026-01-19 10:15:47 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.3785 (0.5694)	loss 0.8503 (0.9884)	grad_norm 9.1692 (inf)	loss_scale 16384.0000 (26639.6336)	mem 2679MB
[2026-01-19 10:15:51 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [3/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2862 (0.5566)	loss 0.9942 (0.9856)	grad_norm 8.4657 (inf)	loss_scale 16384.0000 (25912.2837)	mem 2679MB
[2026-01-19 10:15:52 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 3 training takes 0:01:19
[2026-01-19 10:16:00 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.223 (8.223)	Loss 0.2605 (0.2605)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:16:04 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.085 (1.088)	Loss 0.5234 (0.5344)	Acc@1 87.500 (78.977)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:16:05 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 75.897 Acc@5 0.000
[2026-01-19 10:16:05 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 75.9%
[2026-01-19 10:16:05 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_3.pth saving......
[2026-01-19 10:16:06 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_3.pth saved !!!
[2026-01-19 10:16:06 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 3): 75.90% ***
[2026-01-19 10:16:06 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 75.90%
[2026-01-19 10:16:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][0/146]	eta 0:11:24 lr 0.000003	 wd 0.0000	time 4.6900 (4.6900)	loss 1.0039 (1.0039)	grad_norm 6.3851 (6.3851)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:16:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][10/146]	eta 0:02:05 lr 0.000003	 wd 0.0000	time 0.7000 (0.9217)	loss 0.8304 (0.9782)	grad_norm 9.4147 (inf)	loss_scale 8192.0000 (9681.4545)	mem 2679MB
[2026-01-19 10:16:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][20/146]	eta 0:01:40 lr 0.000003	 wd 0.0000	time 0.3899 (0.7938)	loss 1.1321 (0.9610)	grad_norm 16.7874 (inf)	loss_scale 8192.0000 (8972.1905)	mem 2679MB
[2026-01-19 10:16:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][30/146]	eta 0:01:19 lr 0.000003	 wd 0.0000	time 0.3430 (0.6826)	loss 0.9025 (0.9540)	grad_norm 4.3791 (inf)	loss_scale 8192.0000 (8720.5161)	mem 2679MB
[2026-01-19 10:16:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][40/146]	eta 0:01:11 lr 0.000003	 wd 0.0000	time 0.6589 (0.6791)	loss 1.0566 (0.9505)	grad_norm 14.1220 (inf)	loss_scale 8192.0000 (8591.6098)	mem 2679MB
[2026-01-19 10:16:39 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][50/146]	eta 0:01:02 lr 0.000003	 wd 0.0000	time 0.4003 (0.6526)	loss 0.9004 (0.9482)	grad_norm 8.4235 (inf)	loss_scale 8192.0000 (8513.2549)	mem 2679MB
[2026-01-19 10:16:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][60/146]	eta 0:00:55 lr 0.000003	 wd 0.0000	time 0.4427 (0.6421)	loss 0.9740 (0.9406)	grad_norm 18.8865 (inf)	loss_scale 8192.0000 (8460.5902)	mem 2679MB
[2026-01-19 10:16:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][70/146]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 0.4731 (0.6149)	loss 0.8715 (0.9405)	grad_norm 12.2752 (inf)	loss_scale 8192.0000 (8422.7606)	mem 2679MB
[2026-01-19 10:16:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 1.1930 (0.6063)	loss 0.9062 (0.9266)	grad_norm 10.3235 (inf)	loss_scale 8192.0000 (8394.2716)	mem 2679MB
[2026-01-19 10:17:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.4957 (0.6055)	loss 1.0858 (0.9327)	grad_norm 13.5619 (inf)	loss_scale 8192.0000 (8372.0440)	mem 2679MB
[2026-01-19 10:17:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.4390 (0.5919)	loss 0.8147 (0.9255)	grad_norm 6.8837 (inf)	loss_scale 8192.0000 (8354.2178)	mem 2679MB
[2026-01-19 10:17:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.7339 (0.5821)	loss 0.7071 (0.9211)	grad_norm 11.5687 (inf)	loss_scale 8192.0000 (8339.6036)	mem 2679MB
[2026-01-19 10:17:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.8735 (0.5801)	loss 0.8418 (0.9165)	grad_norm 8.3445 (inf)	loss_scale 8192.0000 (8327.4050)	mem 2679MB
[2026-01-19 10:17:22 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.3887 (0.5765)	loss 0.9246 (0.9122)	grad_norm 11.1432 (inf)	loss_scale 8192.0000 (8317.0687)	mem 2679MB
[2026-01-19 10:17:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [4/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2122 (0.5615)	loss 0.8649 (0.9085)	grad_norm 10.1151 (inf)	loss_scale 8192.0000 (8308.1986)	mem 2679MB
[2026-01-19 10:17:26 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 4 training takes 0:01:20
[2026-01-19 10:17:35 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.510 (8.510)	Loss 0.1757 (0.1757)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:17:39 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.070 (1.121)	Loss 0.3406 (0.3671)	Acc@1 96.875 (89.773)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:17:40 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 86.496 Acc@5 0.000
[2026-01-19 10:17:40 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.5%
[2026-01-19 10:17:40 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_4.pth saving......
[2026-01-19 10:17:40 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_4.pth saved !!!
[2026-01-19 10:17:40 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 4): 86.50% ***
[2026-01-19 10:17:40 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 86.50%
[2026-01-19 10:17:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][0/146]	eta 0:11:41 lr 0.000003	 wd 0.0000	time 4.8040 (4.8040)	loss 0.9516 (0.9516)	grad_norm 6.5903 (6.5903)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:17:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][10/146]	eta 0:02:04 lr 0.000003	 wd 0.0000	time 0.7715 (0.9126)	loss 0.8409 (0.9422)	grad_norm 9.5609 (15.9142)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:17:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][20/146]	eta 0:01:30 lr 0.000003	 wd 0.0000	time 0.3467 (0.7151)	loss 0.9244 (0.9197)	grad_norm 9.1164 (13.8611)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][30/146]	eta 0:01:15 lr 0.000003	 wd 0.0000	time 0.5021 (0.6524)	loss 0.8647 (0.8985)	grad_norm 18.9785 (16.7036)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][40/146]	eta 0:01:08 lr 0.000003	 wd 0.0000	time 0.3718 (0.6471)	loss 0.8599 (0.9040)	grad_norm 11.4647 (16.8476)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:12 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][50/146]	eta 0:00:59 lr 0.000003	 wd 0.0000	time 0.3681 (0.6153)	loss 0.8575 (0.8993)	grad_norm 8.4241 (16.3159)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][60/146]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.4837 (0.6220)	loss 0.9368 (0.8953)	grad_norm 5.6983 (15.6092)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][70/146]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 0.4642 (0.6054)	loss 1.1286 (0.8976)	grad_norm 19.5962 (15.5696)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:28 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][80/146]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.5620 (0.5892)	loss 0.7288 (0.8856)	grad_norm 9.3053 (15.1931)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][90/146]	eta 0:00:32 lr 0.000003	 wd 0.0000	time 0.3911 (0.5885)	loss 1.0002 (0.8872)	grad_norm 19.6616 (15.3258)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:39 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][100/146]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.4161 (0.5835)	loss 0.7524 (0.8881)	grad_norm 12.9262 (15.2934)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.5605 (0.5814)	loss 0.7929 (0.8843)	grad_norm 18.4004 (15.3373)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:51 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 1.6794 (0.5794)	loss 0.8725 (0.8791)	grad_norm 26.4927 (15.3167)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.4902 (0.5687)	loss 0.7727 (0.8787)	grad_norm 17.5018 (15.0785)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:18:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [5/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2023 (0.5605)	loss 0.8342 (0.8795)	grad_norm 8.9497 (14.9776)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:01 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 5 training takes 0:01:20
[2026-01-19 10:19:10 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.031 (9.031)	Loss 0.1370 (0.1370)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:19:13 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.071 (1.108)	Loss 0.3081 (0.3423)	Acc@1 96.875 (88.920)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:19:14 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 85.812 Acc@5 0.000
[2026-01-19 10:19:14 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.8%
[2026-01-19 10:19:14 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 86.50%
[2026-01-19 10:19:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][0/146]	eta 0:08:54 lr 0.000003	 wd 0.0000	time 3.6638 (3.6638)	loss 0.7065 (0.7065)	grad_norm 11.3444 (11.3444)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][10/146]	eta 0:02:03 lr 0.000003	 wd 0.0000	time 0.7244 (0.9108)	loss 0.7886 (0.8626)	grad_norm 10.4067 (12.4157)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][20/146]	eta 0:01:32 lr 0.000003	 wd 0.0000	time 0.4093 (0.7366)	loss 0.7737 (0.8556)	grad_norm 7.1293 (11.8607)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][30/146]	eta 0:01:15 lr 0.000003	 wd 0.0000	time 0.6835 (0.6522)	loss 0.8014 (0.8652)	grad_norm 16.7542 (12.5925)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][40/146]	eta 0:01:09 lr 0.000003	 wd 0.0000	time 1.0048 (0.6584)	loss 0.8311 (0.8616)	grad_norm 11.1919 (13.1365)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:46 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][50/146]	eta 0:01:00 lr 0.000003	 wd 0.0000	time 0.3611 (0.6331)	loss 0.9371 (0.8730)	grad_norm 10.1199 (12.9412)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][60/146]	eta 0:00:54 lr 0.000003	 wd 0.0000	time 0.4562 (0.6284)	loss 0.8691 (0.8675)	grad_norm 6.9769 (12.4451)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:19:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][70/146]	eta 0:00:45 lr 0.000003	 wd 0.0000	time 0.3820 (0.6052)	loss 0.7480 (0.8683)	grad_norm 10.0818 (12.6833)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 2.2020 (0.6091)	loss 0.9650 (0.8698)	grad_norm 9.2501 (12.8473)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.3733 (0.5947)	loss 0.7689 (0.8741)	grad_norm 9.0884 (12.7837)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][100/146]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.4419 (0.5820)	loss 0.9293 (0.8718)	grad_norm 17.9523 (12.7165)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.4680 (0.5833)	loss 0.7281 (0.8665)	grad_norm 14.7773 (12.9268)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.7280 (0.5809)	loss 0.7512 (0.8658)	grad_norm 20.0939 (13.0495)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.7556 (0.5805)	loss 0.7742 (0.8667)	grad_norm 10.4744 (12.9261)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [6/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2180 (0.5609)	loss 0.7715 (0.8687)	grad_norm 20.4754 (13.1199)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:34 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 6 training takes 0:01:20
[2026-01-19 10:20:43 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.125 (9.125)	Loss 0.1143 (0.1143)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:20:47 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.069 (1.136)	Loss 0.3484 (0.3474)	Acc@1 90.625 (88.636)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:20:47 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 85.128 Acc@5 0.000
[2026-01-19 10:20:47 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.1%
[2026-01-19 10:20:47 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 86.50%
[2026-01-19 10:20:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][0/146]	eta 0:12:39 lr 0.000003	 wd 0.0000	time 5.2027 (5.2027)	loss 0.7851 (0.7851)	grad_norm 16.3425 (16.3425)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:20:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][10/146]	eta 0:02:11 lr 0.000003	 wd 0.0000	time 0.4065 (0.9701)	loss 0.6172 (0.8059)	grad_norm 7.4582 (15.1292)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][20/146]	eta 0:01:33 lr 0.000003	 wd 0.0000	time 0.3704 (0.7392)	loss 0.7977 (0.8584)	grad_norm 10.7826 (13.7007)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][30/146]	eta 0:01:21 lr 0.000003	 wd 0.0000	time 0.6862 (0.7065)	loss 0.9403 (0.8586)	grad_norm 8.8837 (14.5205)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:15 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][40/146]	eta 0:01:11 lr 0.000003	 wd 0.0000	time 1.8776 (0.6773)	loss 0.8670 (0.8690)	grad_norm 28.3924 (15.2372)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:20 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][50/146]	eta 0:01:00 lr 0.000003	 wd 0.0000	time 0.5573 (0.6307)	loss 0.8599 (0.8538)	grad_norm 8.2168 (14.7210)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][60/146]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.4586 (0.6209)	loss 0.8343 (0.8483)	grad_norm 6.0443 (14.2476)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:31 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][70/146]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 0.3235 (0.6069)	loss 0.7493 (0.8424)	grad_norm 11.4990 (14.2678)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 0.4332 (0.6066)	loss 0.7747 (0.8419)	grad_norm 8.5193 (13.8183)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.4437 (0.5921)	loss 0.8014 (0.8412)	grad_norm 14.8904 (14.0923)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][100/146]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.3068 (0.5738)	loss 0.7874 (0.8418)	grad_norm 11.1649 (13.9187)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.4636 (0.5769)	loss 0.7388 (0.8440)	grad_norm 12.2932 (14.2617)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:21:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][120/146]	eta 0:00:14 lr 0.000003	 wd 0.0000	time 0.8210 (0.5718)	loss 0.8397 (0.8448)	grad_norm 11.7346 (14.3277)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.2850 (0.5775)	loss 1.0125 (0.8503)	grad_norm 8.2946 (14.3441)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [7/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2144 (0.5588)	loss 0.7109 (0.8497)	grad_norm 9.3481 (14.2381)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:07 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 7 training takes 0:01:19
[2026-01-19 10:22:16 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.943 (8.943)	Loss 0.1041 (0.1041)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:22:19 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.068 (1.092)	Loss 0.3369 (0.3294)	Acc@1 93.750 (88.920)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:22:20 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 85.470 Acc@5 0.000
[2026-01-19 10:22:20 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.5%
[2026-01-19 10:22:20 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 86.50%
[2026-01-19 10:22:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][0/146]	eta 0:10:26 lr 0.000003	 wd 0.0000	time 4.2884 (4.2884)	loss 0.9560 (0.9560)	grad_norm 8.9759 (8.9759)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:31 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][10/146]	eta 0:02:07 lr 0.000003	 wd 0.0000	time 0.4881 (0.9402)	loss 0.9060 (0.8999)	grad_norm 7.3073 (10.1513)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:35 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][20/146]	eta 0:01:30 lr 0.000003	 wd 0.0000	time 0.3880 (0.7196)	loss 0.7705 (0.8847)	grad_norm 7.3314 (11.7434)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][30/146]	eta 0:01:21 lr 0.000003	 wd 0.0000	time 0.3760 (0.7026)	loss 0.9401 (0.8581)	grad_norm 6.4078 (11.6594)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][40/146]	eta 0:01:10 lr 0.000003	 wd 0.0000	time 0.6674 (0.6660)	loss 0.8269 (0.8546)	grad_norm 25.7121 (11.6169)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][50/146]	eta 0:01:00 lr 0.000003	 wd 0.0000	time 0.6424 (0.6337)	loss 0.5878 (0.8618)	grad_norm 8.0708 (11.9697)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:22:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][60/146]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.4872 (0.6258)	loss 0.8561 (0.8638)	grad_norm 9.5291 (11.9512)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][70/146]	eta 0:00:45 lr 0.000003	 wd 0.0000	time 0.5400 (0.6008)	loss 0.8662 (0.8631)	grad_norm 6.9164 (12.2279)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][80/146]	eta 0:00:39 lr 0.000003	 wd 0.0000	time 0.4540 (0.6010)	loss 0.6230 (0.8593)	grad_norm 16.7460 (12.1245)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][90/146]	eta 0:00:32 lr 0.000003	 wd 0.0000	time 0.2397 (0.5832)	loss 0.7160 (0.8562)	grad_norm 7.7354 (12.1688)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 2.0635 (0.5962)	loss 0.9239 (0.8592)	grad_norm 5.9871 (12.2560)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.4394 (0.5863)	loss 0.9891 (0.8621)	grad_norm 20.1293 (12.4125)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:31 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.3636 (0.5809)	loss 0.7986 (0.8606)	grad_norm 17.1978 (12.4114)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:36 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.3839 (0.5805)	loss 1.0169 (0.8601)	grad_norm 8.8095 (12.1635)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:40 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [8/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2175 (0.5647)	loss 0.8064 (0.8583)	grad_norm 14.9556 (12.2683)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:23:41 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 8 training takes 0:01:20
[2026-01-19 10:23:50 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.165 (9.165)	Loss 0.0947 (0.0947)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:23:53 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.068 (1.103)	Loss 0.3101 (0.2933)	Acc@1 96.875 (90.909)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:23:54 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 87.350 Acc@5 0.000
[2026-01-19 10:23:54 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.4%
[2026-01-19 10:23:54 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_8.pth saving......
[2026-01-19 10:23:58 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_8.pth saved !!!
[2026-01-19 10:23:58 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 8): 87.35% ***
[2026-01-19 10:23:58 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 87.35%
[2026-01-19 10:24:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][0/146]	eta 0:12:11 lr 0.000003	 wd 0.0000	time 5.0118 (5.0118)	loss 0.7077 (0.7077)	grad_norm 16.8811 (16.8811)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][10/146]	eta 0:02:03 lr 0.000003	 wd 0.0000	time 0.6393 (0.9104)	loss 0.9559 (0.8123)	grad_norm 16.8496 (13.5200)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][20/146]	eta 0:01:39 lr 0.000003	 wd 0.0000	time 0.4519 (0.7916)	loss 0.6009 (0.8129)	grad_norm 7.5686 (12.4974)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][30/146]	eta 0:01:19 lr 0.000003	 wd 0.0000	time 0.4634 (0.6843)	loss 0.8058 (0.8260)	grad_norm 10.1321 (12.6122)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][40/146]	eta 0:01:06 lr 0.000003	 wd 0.0000	time 0.5214 (0.6289)	loss 0.7895 (0.8348)	grad_norm 9.6420 (12.1127)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][50/146]	eta 0:00:59 lr 0.000003	 wd 0.0000	time 0.4011 (0.6247)	loss 0.7159 (0.8404)	grad_norm 8.1441 (12.2365)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][60/146]	eta 0:00:51 lr 0.000003	 wd 0.0000	time 0.3626 (0.6007)	loss 1.0855 (0.8524)	grad_norm 11.2578 (12.1084)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][70/146]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 0.4328 (0.6081)	loss 1.0499 (0.8534)	grad_norm 18.6620 (12.2859)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][80/146]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.3943 (0.5858)	loss 1.0042 (0.8538)	grad_norm 27.0995 (12.6755)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:51 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][90/146]	eta 0:00:32 lr 0.000003	 wd 0.0000	time 1.0067 (0.5858)	loss 1.0742 (0.8596)	grad_norm 21.9821 (12.7724)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:24:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][100/146]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.3884 (0.5846)	loss 0.8228 (0.8560)	grad_norm 14.7778 (12.6027)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:02 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.8415 (0.5824)	loss 0.7795 (0.8531)	grad_norm 11.0293 (12.3712)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.4312 (0.5799)	loss 0.9318 (0.8537)	grad_norm 18.8702 (12.5122)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.5564 (0.5758)	loss 0.8487 (0.8544)	grad_norm 10.8258 (12.3039)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:17 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [9/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2207 (0.5595)	loss 0.6700 (0.8498)	grad_norm 17.1353 (12.2012)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:18 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 9 training takes 0:01:20
[2026-01-19 10:25:26 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.479 (8.479)	Loss 0.0947 (0.0947)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:25:29 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.071 (1.057)	Loss 0.2581 (0.2524)	Acc@1 96.875 (93.182)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:25:31 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 89.915 Acc@5 0.000
[2026-01-19 10:25:31 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 89.9%
[2026-01-19 10:25:31 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_9.pth saving......
[2026-01-19 10:25:31 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_9.pth saved !!!
[2026-01-19 10:25:31 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 9): 89.91% ***
[2026-01-19 10:25:31 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 89.91%
[2026-01-19 10:25:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][0/146]	eta 0:12:42 lr 0.000003	 wd 0.0000	time 5.2260 (5.2260)	loss 1.0319 (1.0319)	grad_norm 12.4148 (12.4148)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][10/146]	eta 0:02:07 lr 0.000003	 wd 0.0000	time 0.5053 (0.9396)	loss 0.6649 (0.8121)	grad_norm 15.5590 (12.2217)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:47 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][20/146]	eta 0:01:35 lr 0.000003	 wd 0.0000	time 0.4338 (0.7546)	loss 0.8751 (0.7864)	grad_norm 15.8229 (12.0084)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:25:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][30/146]	eta 0:01:18 lr 0.000003	 wd 0.0000	time 0.4701 (0.6809)	loss 0.5882 (0.7685)	grad_norm 9.6949 (11.6513)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][40/146]	eta 0:01:16 lr 0.000003	 wd 0.0000	time 2.3727 (0.7200)	loss 0.6972 (0.7883)	grad_norm 5.6977 (12.2038)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][50/146]	eta 0:01:04 lr 0.000003	 wd 0.0000	time 0.4007 (0.6757)	loss 1.0514 (0.8096)	grad_norm 11.6513 (12.6596)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][60/146]	eta 0:00:55 lr 0.000003	 wd 0.0000	time 0.6394 (0.6408)	loss 0.8500 (0.8119)	grad_norm 9.0286 (12.9971)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][70/146]	eta 0:00:47 lr 0.000003	 wd 0.0000	time 0.3980 (0.6305)	loss 0.5602 (0.8158)	grad_norm 9.3643 (13.1500)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:22 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 1.2461 (0.6199)	loss 0.6692 (0.8149)	grad_norm 18.6893 (13.1244)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:28 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][90/146]	eta 0:00:34 lr 0.000003	 wd 0.0000	time 0.3570 (0.6159)	loss 0.8227 (0.8122)	grad_norm 23.2986 (13.2202)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.3996 (0.6002)	loss 0.6096 (0.8107)	grad_norm 12.1723 (13.1544)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.6271 (0.5895)	loss 0.8408 (0.8089)	grad_norm 13.4231 (13.1108)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:44 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 1.6161 (0.5954)	loss 0.7120 (0.8133)	grad_norm 21.8273 (13.2389)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.4300 (0.5873)	loss 0.9572 (0.8172)	grad_norm 16.7200 (13.2767)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [10/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2429 (0.5699)	loss 0.9135 (0.8200)	grad_norm 25.4102 (13.1422)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:26:53 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 10 training takes 0:01:21
[2026-01-19 10:27:01 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.946 (7.946)	Loss 0.0730 (0.0730)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:27:05 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.084 (1.053)	Loss 0.3149 (0.2956)	Acc@1 96.875 (90.057)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:27:06 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 86.496 Acc@5 0.000
[2026-01-19 10:27:06 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.5%
[2026-01-19 10:27:06 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 89.91%
[2026-01-19 10:27:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][0/146]	eta 0:13:26 lr 0.000003	 wd 0.0000	time 5.5257 (5.5257)	loss 0.9167 (0.9167)	grad_norm 11.7936 (11.7936)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][10/146]	eta 0:02:05 lr 0.000003	 wd 0.0000	time 0.4414 (0.9220)	loss 0.9546 (0.8515)	grad_norm 12.0974 (12.1047)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][20/146]	eta 0:01:32 lr 0.000003	 wd 0.0000	time 0.2993 (0.7334)	loss 0.9189 (0.8481)	grad_norm 16.9887 (12.9313)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:26 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][30/146]	eta 0:01:14 lr 0.000003	 wd 0.0000	time 0.4046 (0.6399)	loss 0.9639 (0.8614)	grad_norm 28.2139 (12.6155)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][40/146]	eta 0:01:08 lr 0.000003	 wd 0.0000	time 0.7903 (0.6483)	loss 0.6127 (0.8440)	grad_norm 14.8390 (13.2728)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][50/146]	eta 0:00:57 lr 0.000003	 wd 0.0000	time 0.3205 (0.6021)	loss 0.8083 (0.8263)	grad_norm 13.1075 (12.8699)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][60/146]	eta 0:00:50 lr 0.000003	 wd 0.0000	time 0.3846 (0.5847)	loss 1.0103 (0.8206)	grad_norm 8.5244 (12.2986)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][70/146]	eta 0:00:44 lr 0.000003	 wd 0.0000	time 0.4016 (0.5919)	loss 0.7922 (0.8210)	grad_norm 21.6404 (12.4876)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:27:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][80/146]	eta 0:00:38 lr 0.000003	 wd 0.0000	time 0.4791 (0.5782)	loss 0.9316 (0.8225)	grad_norm 8.9981 (12.6748)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 1.1820 (0.5925)	loss 0.8213 (0.8263)	grad_norm 7.4765 (12.5237)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][100/146]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.4648 (0.5803)	loss 0.7249 (0.8296)	grad_norm 7.3359 (12.4184)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.5647 (0.5739)	loss 1.0029 (0.8283)	grad_norm 15.1498 (12.5588)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:15 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][120/146]	eta 0:00:14 lr 0.000003	 wd 0.0000	time 0.3607 (0.5716)	loss 0.6660 (0.8254)	grad_norm 9.5896 (12.6273)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:20 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.4407 (0.5665)	loss 0.6660 (0.8227)	grad_norm 7.1647 (12.4287)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [11/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2699 (0.5565)	loss 0.7846 (0.8203)	grad_norm 6.0938 (12.2988)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:26 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 11 training takes 0:01:19
[2026-01-19 10:28:34 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.945 (7.945)	Loss 0.0732 (0.0732)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:28:37 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.070 (1.046)	Loss 0.3225 (0.2879)	Acc@1 96.875 (90.625)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:28:38 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 87.179 Acc@5 0.000
[2026-01-19 10:28:38 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.2%
[2026-01-19 10:28:38 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 89.91%
[2026-01-19 10:28:43 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][0/146]	eta 0:10:59 lr 0.000003	 wd 0.0000	time 4.5145 (4.5145)	loss 0.5376 (0.5376)	grad_norm 6.6534 (6.6534)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][10/146]	eta 0:02:01 lr 0.000003	 wd 0.0000	time 0.3741 (0.8962)	loss 1.0209 (0.8329)	grad_norm 11.4150 (14.0528)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:54 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][20/146]	eta 0:01:33 lr 0.000003	 wd 0.0000	time 0.4229 (0.7446)	loss 0.8408 (0.8304)	grad_norm 7.7195 (13.6729)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:28:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][30/146]	eta 0:01:18 lr 0.000003	 wd 0.0000	time 0.4902 (0.6789)	loss 0.6895 (0.8042)	grad_norm 11.0631 (12.4208)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][40/146]	eta 0:01:09 lr 0.000003	 wd 0.0000	time 0.4308 (0.6593)	loss 0.7677 (0.8056)	grad_norm 7.0597 (12.7377)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][50/146]	eta 0:01:01 lr 0.000003	 wd 0.0000	time 0.4293 (0.6386)	loss 0.7026 (0.8197)	grad_norm 15.8097 (13.5497)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][60/146]	eta 0:00:53 lr 0.000002	 wd 0.0000	time 0.6917 (0.6195)	loss 1.0321 (0.8248)	grad_norm 17.2548 (13.6051)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.3778 (0.6062)	loss 0.9537 (0.8163)	grad_norm 16.9397 (13.3218)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:26 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][80/146]	eta 0:00:38 lr 0.000002	 wd 0.0000	time 0.4284 (0.5891)	loss 0.8315 (0.8231)	grad_norm 11.4601 (13.5740)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][90/146]	eta 0:00:32 lr 0.000002	 wd 0.0000	time 0.5046 (0.5851)	loss 0.7515 (0.8165)	grad_norm 5.8492 (13.4482)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:36 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][100/146]	eta 0:00:26 lr 0.000002	 wd 0.0000	time 0.4529 (0.5744)	loss 0.9292 (0.8133)	grad_norm 8.3048 (13.1545)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.4196 (0.5646)	loss 0.7119 (0.8147)	grad_norm 12.2261 (13.0135)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:49 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 1.0199 (0.5803)	loss 1.0001 (0.8103)	grad_norm 9.8467 (12.8511)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4149 (0.5723)	loss 0.7046 (0.8149)	grad_norm 15.1000 (12.8931)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [12/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2464 (0.5591)	loss 1.1965 (0.8211)	grad_norm 12.1288 (13.2603)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:29:58 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 12 training takes 0:01:20
[2026-01-19 10:30:06 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.656 (7.656)	Loss 0.0684 (0.0684)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:30:11 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.088 (1.105)	Loss 0.3462 (0.3003)	Acc@1 96.875 (89.773)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:30:11 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 86.838 Acc@5 0.000
[2026-01-19 10:30:11 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.8%
[2026-01-19 10:30:11 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 89.91%
[2026-01-19 10:30:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][0/146]	eta 0:09:58 lr 0.000002	 wd 0.0000	time 4.0973 (4.0973)	loss 0.8253 (0.8253)	grad_norm 12.2764 (12.2764)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][10/146]	eta 0:01:59 lr 0.000002	 wd 0.0000	time 0.6866 (0.8799)	loss 0.7754 (0.8677)	grad_norm 16.3234 (12.5268)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][20/146]	eta 0:01:35 lr 0.000002	 wd 0.0000	time 0.4131 (0.7598)	loss 0.8218 (0.8127)	grad_norm 16.9926 (12.4521)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][30/146]	eta 0:01:17 lr 0.000002	 wd 0.0000	time 0.4250 (0.6667)	loss 0.9310 (0.8194)	grad_norm 9.2252 (12.4195)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:38 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][40/146]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.3940 (0.6562)	loss 0.7884 (0.8178)	grad_norm 6.4748 (12.3274)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:44 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][50/146]	eta 0:01:01 lr 0.000002	 wd 0.0000	time 0.4497 (0.6393)	loss 0.6511 (0.8091)	grad_norm 6.2115 (12.0645)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:49 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][60/146]	eta 0:00:53 lr 0.000002	 wd 0.0000	time 0.6216 (0.6201)	loss 0.8127 (0.8063)	grad_norm 13.2828 (12.4064)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:30:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.3940 (0.6122)	loss 0.7281 (0.8040)	grad_norm 10.6610 (12.6613)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.4159 (0.5937)	loss 0.6831 (0.8047)	grad_norm 11.2003 (13.0762)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][90/146]	eta 0:00:34 lr 0.000002	 wd 0.0000	time 0.3436 (0.6079)	loss 0.7894 (0.8050)	grad_norm 23.9331 (13.2986)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:12 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.3494 (0.5972)	loss 0.8268 (0.8043)	grad_norm 10.9180 (13.2432)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:17 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.5153 (0.5909)	loss 0.7070 (0.8064)	grad_norm 12.0788 (13.1799)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.4515 (0.5783)	loss 0.8558 (0.8085)	grad_norm 33.3682 (13.5377)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:26 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.3799 (0.5689)	loss 0.9304 (0.8082)	grad_norm 10.4497 (13.3877)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [13/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2029 (0.5599)	loss 0.8462 (0.8082)	grad_norm 8.1079 (13.2213)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:31:32 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 13 training takes 0:01:20
[2026-01-19 10:31:39 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.213 (7.213)	Loss 0.0738 (0.0738)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:31:44 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.080 (1.120)	Loss 0.2710 (0.2480)	Acc@1 96.875 (93.182)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:31:45 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.085 Acc@5 0.000
[2026-01-19 10:31:45 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.1%
[2026-01-19 10:31:45 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_13.pth saving......
[2026-01-19 10:31:51 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_13.pth saved !!!
[2026-01-19 10:31:51 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 13): 90.09% ***
[2026-01-19 10:31:51 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.09%
[2026-01-19 10:31:56 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][0/146]	eta 0:14:09 lr 0.000002	 wd 0.0000	time 5.8198 (5.8198)	loss 0.8481 (0.8481)	grad_norm 20.4610 (20.4610)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][10/146]	eta 0:02:13 lr 0.000002	 wd 0.0000	time 0.4287 (0.9843)	loss 0.6750 (0.8737)	grad_norm 9.5870 (15.7657)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][20/146]	eta 0:01:40 lr 0.000002	 wd 0.0000	time 0.7157 (0.7984)	loss 0.9108 (0.8444)	grad_norm 10.0017 (14.5786)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][30/146]	eta 0:01:22 lr 0.000002	 wd 0.0000	time 0.4297 (0.7084)	loss 0.8491 (0.8426)	grad_norm 15.5245 (14.2775)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][40/146]	eta 0:01:12 lr 0.000002	 wd 0.0000	time 1.5002 (0.6860)	loss 1.0073 (0.8283)	grad_norm 24.9341 (14.5319)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][50/146]	eta 0:01:02 lr 0.000002	 wd 0.0000	time 0.3635 (0.6536)	loss 0.8393 (0.8141)	grad_norm 12.1189 (13.7254)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][60/146]	eta 0:00:53 lr 0.000002	 wd 0.0000	time 0.4340 (0.6247)	loss 0.8481 (0.8197)	grad_norm 7.8013 (13.6689)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.6492 (0.6167)	loss 0.8614 (0.8134)	grad_norm 11.8125 (13.3160)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:39 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.3888 (0.5975)	loss 0.9165 (0.8090)	grad_norm 13.9852 (13.0452)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:44 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][90/146]	eta 0:00:32 lr 0.000002	 wd 0.0000	time 0.4284 (0.5880)	loss 1.0342 (0.8152)	grad_norm 8.3995 (13.2308)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:51 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.4396 (0.5942)	loss 0.7583 (0.8146)	grad_norm 5.2702 (13.1983)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:32:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.3890 (0.5793)	loss 0.7951 (0.8153)	grad_norm 5.5570 (13.0744)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 2.4487 (0.5953)	loss 0.7919 (0.8179)	grad_norm 18.8040 (13.3282)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4261 (0.5813)	loss 0.7453 (0.8169)	grad_norm 30.2639 (13.2697)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [14/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2160 (0.5615)	loss 0.9146 (0.8184)	grad_norm 12.6166 (13.2966)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:11 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 14 training takes 0:01:20
[2026-01-19 10:33:20 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.239 (9.239)	Loss 0.0710 (0.0710)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:33:23 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.068 (1.090)	Loss 0.3125 (0.2743)	Acc@1 96.875 (91.477)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:33:24 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 88.034 Acc@5 0.000
[2026-01-19 10:33:24 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 88.0%
[2026-01-19 10:33:24 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.09%
[2026-01-19 10:33:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][0/146]	eta 0:11:01 lr 0.000002	 wd 0.0000	time 4.5286 (4.5286)	loss 0.8059 (0.8059)	grad_norm 8.3128 (8.3128)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][10/146]	eta 0:02:00 lr 0.000002	 wd 0.0000	time 0.8823 (0.8863)	loss 0.8284 (0.8010)	grad_norm 10.0698 (11.8131)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:40 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][20/146]	eta 0:01:32 lr 0.000002	 wd 0.0000	time 0.5950 (0.7375)	loss 0.5898 (0.7952)	grad_norm 17.8053 (11.6506)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][30/146]	eta 0:01:17 lr 0.000002	 wd 0.0000	time 0.6116 (0.6672)	loss 0.7069 (0.7977)	grad_norm 12.8000 (12.2897)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][40/146]	eta 0:01:06 lr 0.000002	 wd 0.0000	time 0.4260 (0.6246)	loss 0.6315 (0.7925)	grad_norm 7.0701 (12.4406)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:33:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][50/146]	eta 0:01:01 lr 0.000002	 wd 0.0000	time 1.0762 (0.6419)	loss 0.8913 (0.7998)	grad_norm 12.5947 (12.1829)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:02 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][60/146]	eta 0:00:52 lr 0.000002	 wd 0.0000	time 0.3109 (0.6139)	loss 1.0521 (0.8019)	grad_norm 12.7119 (12.7518)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.4658 (0.6157)	loss 0.9685 (0.8011)	grad_norm 8.2487 (12.8367)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.4418 (0.5981)	loss 0.9148 (0.8080)	grad_norm 10.4937 (12.9076)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.9548 (0.6005)	loss 0.7302 (0.8070)	grad_norm 6.4019 (12.8206)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.4421 (0.5883)	loss 0.9714 (0.8080)	grad_norm 11.4757 (12.7922)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:28 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.4945 (0.5758)	loss 0.8670 (0.8059)	grad_norm 15.8235 (12.8436)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:35 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.3862 (0.5851)	loss 0.6433 (0.8028)	grad_norm 14.9005 (12.8062)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 1.8902 (0.5868)	loss 0.9581 (0.8077)	grad_norm 47.3314 (12.9794)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:43 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [15/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2023 (0.5617)	loss 0.8684 (0.8093)	grad_norm 12.1807 (12.9232)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:34:45 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 15 training takes 0:01:20
[2026-01-19 10:34:53 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.396 (8.396)	Loss 0.0623 (0.0623)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:34:56 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.081 (1.052)	Loss 0.3120 (0.2735)	Acc@1 96.875 (90.625)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:34:58 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 87.521 Acc@5 0.000
[2026-01-19 10:34:58 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.5%
[2026-01-19 10:34:58 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.09%
[2026-01-19 10:35:02 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][0/146]	eta 0:11:04 lr 0.000002	 wd 0.0000	time 4.5511 (4.5511)	loss 0.9005 (0.9005)	grad_norm 70.4341 (70.4341)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][10/146]	eta 0:01:54 lr 0.000002	 wd 0.0000	time 0.4266 (0.8423)	loss 0.9911 (0.7979)	grad_norm 9.4642 (18.7089)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][20/146]	eta 0:01:35 lr 0.000002	 wd 0.0000	time 1.0562 (0.7598)	loss 0.6728 (0.7904)	grad_norm 13.9558 (16.0913)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][30/146]	eta 0:01:18 lr 0.000002	 wd 0.0000	time 0.3964 (0.6795)	loss 0.7349 (0.7767)	grad_norm 17.5969 (14.4139)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][40/146]	eta 0:01:08 lr 0.000002	 wd 0.0000	time 0.6601 (0.6430)	loss 0.9915 (0.7891)	grad_norm 8.2019 (14.2911)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][50/146]	eta 0:00:58 lr 0.000002	 wd 0.0000	time 0.5261 (0.6073)	loss 0.8050 (0.8024)	grad_norm 12.9941 (14.5981)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][60/146]	eta 0:00:50 lr 0.000002	 wd 0.0000	time 0.9214 (0.5905)	loss 0.7390 (0.8012)	grad_norm 13.7780 (14.5583)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:40 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][70/146]	eta 0:00:44 lr 0.000002	 wd 0.0000	time 0.3869 (0.5912)	loss 0.8936 (0.8093)	grad_norm 13.8021 (14.5379)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][80/146]	eta 0:00:38 lr 0.000002	 wd 0.0000	time 0.6523 (0.5800)	loss 0.7478 (0.8106)	grad_norm 15.9649 (14.6580)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][90/146]	eta 0:00:32 lr 0.000002	 wd 0.0000	time 0.5871 (0.5787)	loss 0.8585 (0.8092)	grad_norm 11.3347 (14.3359)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:35:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 2.0068 (0.5985)	loss 0.6008 (0.8183)	grad_norm 12.7474 (14.3879)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:04 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.6332 (0.5929)	loss 0.8891 (0.8213)	grad_norm 10.2642 (14.0352)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.3850 (0.5861)	loss 0.5678 (0.8236)	grad_norm 7.5498 (13.7296)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4167 (0.5750)	loss 0.8327 (0.8188)	grad_norm 14.7509 (13.6502)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:17 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [16/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2853 (0.5616)	loss 0.7742 (0.8184)	grad_norm 5.8366 (13.4603)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:18 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 16 training takes 0:01:20
[2026-01-19 10:36:26 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.926 (7.926)	Loss 0.0771 (0.0771)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:36:30 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.086 (1.089)	Loss 0.2915 (0.2622)	Acc@1 96.875 (92.898)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:36:31 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 89.402 Acc@5 0.000
[2026-01-19 10:36:31 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 89.4%
[2026-01-19 10:36:31 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.09%
[2026-01-19 10:36:35 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][0/146]	eta 0:09:26 lr 0.000002	 wd 0.0000	time 3.8820 (3.8820)	loss 0.9531 (0.9531)	grad_norm 16.9167 (16.9167)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][10/146]	eta 0:02:05 lr 0.000002	 wd 0.0000	time 0.9729 (0.9237)	loss 0.6730 (0.8670)	grad_norm 7.4189 (12.8616)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:47 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][20/146]	eta 0:01:35 lr 0.000002	 wd 0.0000	time 0.4154 (0.7542)	loss 0.7134 (0.7982)	grad_norm 9.5784 (11.5054)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][30/146]	eta 0:01:18 lr 0.000002	 wd 0.0000	time 0.4028 (0.6736)	loss 0.7497 (0.7997)	grad_norm 17.8024 (12.3841)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:36:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][40/146]	eta 0:01:10 lr 0.000002	 wd 0.0000	time 0.4446 (0.6659)	loss 0.8833 (0.8098)	grad_norm 13.6921 (11.9616)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:04 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][50/146]	eta 0:01:01 lr 0.000002	 wd 0.0000	time 1.7001 (0.6442)	loss 0.5786 (0.8213)	grad_norm 4.2445 (11.8727)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][60/146]	eta 0:00:53 lr 0.000002	 wd 0.0000	time 0.7703 (0.6207)	loss 0.9504 (0.8244)	grad_norm 13.3166 (12.0016)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][70/146]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.3375 (0.6030)	loss 0.9855 (0.8207)	grad_norm 6.3252 (11.8235)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][80/146]	eta 0:00:38 lr 0.000002	 wd 0.0000	time 0.4442 (0.5836)	loss 0.7572 (0.8248)	grad_norm 14.1127 (12.0299)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.7447 (0.5947)	loss 0.8737 (0.8278)	grad_norm 19.1955 (12.0048)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:31 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.3987 (0.5896)	loss 0.7360 (0.8301)	grad_norm 8.2026 (12.0571)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:37:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.5137 (0.5900)	loss 0.7429 (0.8229)	grad_norm 14.8947 (12.1248)	loss_scale 16384.0000 (8708.6126)	mem 2679MB
[2026-01-19 10:37:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.4115 (0.5800)	loss 1.0016 (0.8271)	grad_norm 13.3044 (12.1154)	loss_scale 16384.0000 (9342.9421)	mem 2679MB
[2026-01-19 10:37:47 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.7403 (0.5767)	loss 0.7634 (0.8246)	grad_norm 10.6382 (12.2880)	loss_scale 16384.0000 (9880.4275)	mem 2679MB
[2026-01-19 10:37:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [17/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2010 (0.5625)	loss 0.8785 (0.8241)	grad_norm 5.2426 (12.1769)	loss_scale 16384.0000 (10341.6738)	mem 2679MB
[2026-01-19 10:37:52 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 17 training takes 0:01:20
[2026-01-19 10:37:59 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.740 (7.740)	Loss 0.0691 (0.0691)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:38:04 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.074 (1.097)	Loss 0.3025 (0.2669)	Acc@1 96.875 (92.330)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:38:04 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 89.060 Acc@5 0.000
[2026-01-19 10:38:04 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 89.1%
[2026-01-19 10:38:04 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.09%
[2026-01-19 10:38:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][0/146]	eta 0:12:24 lr 0.000001	 wd 0.0000	time 5.0974 (5.0974)	loss 0.7234 (0.7234)	grad_norm 12.5388 (12.5388)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][10/146]	eta 0:02:21 lr 0.000001	 wd 0.0000	time 0.4034 (1.0416)	loss 0.8174 (0.8187)	grad_norm 7.4683 (10.6122)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][20/146]	eta 0:01:36 lr 0.000001	 wd 0.0000	time 0.3981 (0.7646)	loss 0.7554 (0.8460)	grad_norm 9.0075 (11.0176)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:26 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][30/146]	eta 0:01:22 lr 0.000001	 wd 0.0000	time 0.6242 (0.7077)	loss 0.7951 (0.8281)	grad_norm 12.9224 (11.4766)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][40/146]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 0.7160 (0.6878)	loss 0.9050 (0.8192)	grad_norm 8.4772 (11.2256)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:38 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][50/146]	eta 0:01:02 lr 0.000001	 wd 0.0000	time 0.4023 (0.6532)	loss 0.8550 (0.8210)	grad_norm 12.2157 (11.4553)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:43 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][60/146]	eta 0:00:54 lr 0.000001	 wd 0.0000	time 0.4257 (0.6377)	loss 0.8591 (0.8157)	grad_norm 6.0624 (11.1693)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.4177 (0.6080)	loss 0.7132 (0.8152)	grad_norm 11.4722 (11.1530)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:38:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][80/146]	eta 0:00:39 lr 0.000001	 wd 0.0000	time 0.4461 (0.5926)	loss 0.7333 (0.8164)	grad_norm 9.7676 (11.0346)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][90/146]	eta 0:00:34 lr 0.000001	 wd 0.0000	time 0.3839 (0.6104)	loss 0.8119 (0.8201)	grad_norm 8.5195 (11.3047)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.3301 (0.5957)	loss 0.8084 (0.8212)	grad_norm 13.7551 (11.6390)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.3844 (0.5926)	loss 0.6793 (0.8131)	grad_norm 11.6898 (11.9073)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:15 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.4303 (0.5810)	loss 0.6650 (0.8092)	grad_norm 7.7743 (12.1284)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:20 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.7564 (0.5772)	loss 0.6744 (0.8039)	grad_norm 14.6402 (12.1617)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [18/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2075 (0.5595)	loss 0.5178 (0.8040)	grad_norm 5.7945 (12.1943)	loss_scale 16384.0000 (16384.0000)	mem 2679MB
[2026-01-19 10:39:25 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 18 training takes 0:01:20
[2026-01-19 10:39:33 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.238 (8.238)	Loss 0.0641 (0.0641)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:39:37 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.072 (1.105)	Loss 0.2751 (0.2454)	Acc@1 96.875 (93.466)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:39:38 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.256 Acc@5 0.000
[2026-01-19 10:39:38 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.3%
[2026-01-19 10:39:38 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_18.pth saving......
[2026-01-19 10:39:41 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_18.pth saved !!!
[2026-01-19 10:39:41 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 18): 90.26% ***
[2026-01-19 10:39:41 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.26%
[2026-01-19 10:39:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][0/146]	eta 0:10:19 lr 0.000001	 wd 0.0000	time 4.2413 (4.2413)	loss 0.7947 (0.7947)	grad_norm 11.7387 (11.7387)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:39:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][10/146]	eta 0:02:21 lr 0.000001	 wd 0.0000	time 0.5402 (1.0431)	loss 0.8675 (0.7567)	grad_norm 19.8844 (14.2200)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:39:57 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][20/146]	eta 0:01:37 lr 0.000001	 wd 0.0000	time 0.4241 (0.7701)	loss 0.7486 (0.7510)	grad_norm 5.8079 (13.6760)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][30/146]	eta 0:01:21 lr 0.000001	 wd 0.0000	time 0.4970 (0.7058)	loss 0.9096 (0.7610)	grad_norm 13.2899 (13.3182)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 1.2490 (0.6585)	loss 0.8155 (0.7846)	grad_norm 11.0629 (13.2298)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][50/146]	eta 0:01:00 lr 0.000001	 wd 0.0000	time 0.7352 (0.6257)	loss 0.6989 (0.7855)	grad_norm 10.8630 (12.9532)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][60/146]	eta 0:00:54 lr 0.000001	 wd 0.0000	time 0.3857 (0.6309)	loss 0.7141 (0.7867)	grad_norm 11.7183 (12.1094)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][70/146]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.6424 (0.6238)	loss 0.7288 (0.7827)	grad_norm 9.8213 (11.9474)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 0.2980 (0.6124)	loss 0.7521 (0.7850)	grad_norm 13.5887 (11.9117)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:35 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][90/146]	eta 0:00:33 lr 0.000001	 wd 0.0000	time 0.3967 (0.5965)	loss 0.9802 (0.7841)	grad_norm 18.0879 (11.9850)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.4136 (0.5994)	loss 0.9762 (0.7887)	grad_norm 17.8506 (12.1747)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:46 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.4077 (0.5908)	loss 0.6873 (0.7858)	grad_norm 18.0860 (12.4836)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:52 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.7274 (0.5858)	loss 0.8682 (0.7827)	grad_norm 10.5007 (12.3710)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:40:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.3644 (0.5881)	loss 0.6601 (0.7828)	grad_norm 21.5190 (12.2891)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [19/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2012 (0.5642)	loss 0.7428 (0.7833)	grad_norm 9.8429 (12.1367)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:01 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 19 training takes 0:01:20
[2026-01-19 10:41:10 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.034 (9.034)	Loss 0.0646 (0.0646)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:41:14 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.070 (1.107)	Loss 0.2644 (0.2374)	Acc@1 96.875 (94.034)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:41:14 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.940 Acc@5 0.000
[2026-01-19 10:41:14 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.9%
[2026-01-19 10:41:14 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_19.pth saving......
[2026-01-19 10:41:15 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_19.pth saved !!!
[2026-01-19 10:41:15 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 19): 90.94% ***
[2026-01-19 10:41:15 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 90.94%
[2026-01-19 10:41:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][0/146]	eta 0:14:48 lr 0.000001	 wd 0.0000	time 6.0827 (6.0827)	loss 0.7684 (0.7684)	grad_norm 32.4234 (32.4234)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][10/146]	eta 0:02:24 lr 0.000001	 wd 0.0000	time 0.3836 (1.0605)	loss 0.8278 (0.8477)	grad_norm 14.1462 (16.2975)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][20/146]	eta 0:01:44 lr 0.000001	 wd 0.0000	time 0.5051 (0.8328)	loss 0.8309 (0.8585)	grad_norm 8.5601 (14.0867)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][30/146]	eta 0:01:21 lr 0.000001	 wd 0.0000	time 0.4514 (0.7058)	loss 0.8545 (0.8158)	grad_norm 8.9168 (12.7764)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.4282 (0.6538)	loss 0.8002 (0.8158)	grad_norm 13.3632 (13.2750)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:49 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][50/146]	eta 0:01:03 lr 0.000001	 wd 0.0000	time 0.4372 (0.6625)	loss 0.9033 (0.8188)	grad_norm 19.3921 (12.8658)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][60/146]	eta 0:00:53 lr 0.000001	 wd 0.0000	time 0.4085 (0.6238)	loss 0.6667 (0.8114)	grad_norm 10.8024 (12.2560)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:41:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][70/146]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.2290 (0.6220)	loss 0.8954 (0.8159)	grad_norm 22.6262 (12.2349)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 0.9304 (0.6077)	loss 0.7179 (0.8170)	grad_norm 18.0624 (12.3854)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][90/146]	eta 0:00:33 lr 0.000001	 wd 0.0000	time 0.6287 (0.6023)	loss 0.9881 (0.8185)	grad_norm 15.2460 (12.3044)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:15 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.4307 (0.5951)	loss 0.8980 (0.8187)	grad_norm 14.8322 (12.2487)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.4734 (0.5879)	loss 0.7615 (0.8175)	grad_norm 12.9546 (12.3782)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.5075 (0.5951)	loss 0.5715 (0.8177)	grad_norm 12.9646 (12.1798)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.4128 (0.5821)	loss 1.0284 (0.8175)	grad_norm 18.5952 (12.1086)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [20/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2079 (0.5609)	loss 0.6988 (0.8146)	grad_norm 10.4244 (12.0564)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:42:36 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 20 training takes 0:01:20
[2026-01-19 10:42:44 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.403 (8.403)	Loss 0.0717 (0.0717)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:42:48 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.070 (1.090)	Loss 0.2649 (0.2380)	Acc@1 96.875 (94.034)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:42:48 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 91.111 Acc@5 0.000
[2026-01-19 10:42:48 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 91.1%
[2026-01-19 10:42:48 swin_tiny_patch4_window7_224] (utils.py 146): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_20.pth saving......
[2026-01-19 10:42:49 swin_tiny_patch4_window7_224] (utils.py 148): INFO output/swin_tiny_patch4_window7_224/default/ckpt_epoch_20.pth saved !!!
[2026-01-19 10:42:49 swin_tiny_patch4_window7_224] (main.py 177): INFO *** New Best Model Saved (Epoch 20): 91.11% ***
[2026-01-19 10:42:49 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:42:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][0/146]	eta 0:13:06 lr 0.000001	 wd 0.0000	time 5.3862 (5.3862)	loss 0.8633 (0.8633)	grad_norm 14.0209 (14.0209)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][10/146]	eta 0:02:09 lr 0.000001	 wd 0.0000	time 0.8151 (0.9510)	loss 0.5807 (0.8100)	grad_norm 9.5993 (13.2535)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][20/146]	eta 0:01:41 lr 0.000001	 wd 0.0000	time 0.4410 (0.8030)	loss 0.7857 (0.8038)	grad_norm 14.4329 (13.6236)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][30/146]	eta 0:01:19 lr 0.000001	 wd 0.0000	time 0.3295 (0.6828)	loss 0.6803 (0.8229)	grad_norm 3.6240 (13.0309)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][40/146]	eta 0:01:12 lr 0.000001	 wd 0.0000	time 1.9856 (0.6850)	loss 0.8327 (0.8074)	grad_norm 7.4425 (12.7350)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:22 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][50/146]	eta 0:01:01 lr 0.000001	 wd 0.0000	time 0.5236 (0.6454)	loss 0.7445 (0.8123)	grad_norm 8.7130 (13.0939)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][60/146]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.4446 (0.6141)	loss 0.7521 (0.8093)	grad_norm 7.7880 (12.9970)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][70/146]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.3751 (0.6045)	loss 0.7928 (0.8067)	grad_norm 27.2406 (13.1296)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][80/146]	eta 0:00:38 lr 0.000001	 wd 0.0000	time 0.4738 (0.5892)	loss 0.9327 (0.8068)	grad_norm 10.5577 (13.3010)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:43 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][90/146]	eta 0:00:32 lr 0.000001	 wd 0.0000	time 1.1885 (0.5863)	loss 0.8244 (0.8083)	grad_norm 32.9359 (13.2457)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][100/146]	eta 0:00:26 lr 0.000001	 wd 0.0000	time 0.4551 (0.5833)	loss 0.7510 (0.8077)	grad_norm 11.3070 (13.0753)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][110/146]	eta 0:00:20 lr 0.000001	 wd 0.0000	time 0.4326 (0.5751)	loss 1.0951 (0.8066)	grad_norm 16.1539 (13.2328)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:43:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][120/146]	eta 0:00:14 lr 0.000001	 wd 0.0000	time 0.4312 (0.5760)	loss 0.6062 (0.8044)	grad_norm 10.6363 (13.6167)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 1.7202 (0.5747)	loss 0.7658 (0.8000)	grad_norm 23.9383 (13.5522)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [21/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2010 (0.5599)	loss 0.6736 (0.8033)	grad_norm 15.7978 (13.4633)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:10 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 21 training takes 0:01:20
[2026-01-19 10:44:18 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.973 (7.973)	Loss 0.0614 (0.0614)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:44:21 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.077 (1.044)	Loss 0.2769 (0.2414)	Acc@1 96.875 (94.034)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:44:23 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 91.111 Acc@5 0.000
[2026-01-19 10:44:23 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 91.1%
[2026-01-19 10:44:23 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:44:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][0/146]	eta 0:09:58 lr 0.000001	 wd 0.0000	time 4.1016 (4.1016)	loss 0.7842 (0.7842)	grad_norm 6.3607 (6.3607)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][10/146]	eta 0:01:50 lr 0.000001	 wd 0.0000	time 0.3519 (0.8152)	loss 0.6842 (0.8104)	grad_norm 5.5769 (11.7711)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:38 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][20/146]	eta 0:01:31 lr 0.000001	 wd 0.0000	time 0.4090 (0.7237)	loss 0.7349 (0.8212)	grad_norm 8.7939 (10.9728)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:43 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][30/146]	eta 0:01:15 lr 0.000001	 wd 0.0000	time 0.4309 (0.6499)	loss 0.6806 (0.8267)	grad_norm 11.7769 (11.4061)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:49 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 1.7421 (0.6534)	loss 0.6138 (0.8161)	grad_norm 13.3967 (11.6482)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:44:56 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][50/146]	eta 0:01:02 lr 0.000001	 wd 0.0000	time 0.3568 (0.6532)	loss 0.9857 (0.8187)	grad_norm 10.0849 (11.9870)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][60/146]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.6899 (0.6150)	loss 0.9385 (0.8239)	grad_norm 35.1663 (13.1401)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.3850 (0.6164)	loss 0.8877 (0.8197)	grad_norm 7.7558 (12.6581)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][80/146]	eta 0:00:39 lr 0.000001	 wd 0.0000	time 1.2215 (0.6016)	loss 0.9878 (0.8157)	grad_norm 16.1782 (12.6825)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:17 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][90/146]	eta 0:00:33 lr 0.000001	 wd 0.0000	time 0.4384 (0.5945)	loss 0.8193 (0.8225)	grad_norm 13.2089 (12.8042)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][100/146]	eta 0:00:26 lr 0.000001	 wd 0.0000	time 0.4442 (0.5835)	loss 0.6073 (0.8197)	grad_norm 4.1659 (12.7102)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][110/146]	eta 0:00:20 lr 0.000001	 wd 0.0000	time 0.6651 (0.5814)	loss 0.5063 (0.8192)	grad_norm 8.7758 (12.8286)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 1.1295 (0.5858)	loss 0.7752 (0.8161)	grad_norm 12.3099 (12.9797)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:39 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.3860 (0.5807)	loss 0.8346 (0.8120)	grad_norm 13.3234 (13.0350)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:41 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [22/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2100 (0.5594)	loss 0.8363 (0.8147)	grad_norm 12.8062 (13.1053)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:45:43 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 22 training takes 0:01:20
[2026-01-19 10:45:50 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.795 (7.795)	Loss 0.0601 (0.0601)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:45:55 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.076 (1.086)	Loss 0.3047 (0.2578)	Acc@1 96.875 (92.898)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:45:56 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 89.231 Acc@5 0.000
[2026-01-19 10:45:56 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 89.2%
[2026-01-19 10:45:56 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:45:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][0/146]	eta 0:09:01 lr 0.000001	 wd 0.0000	time 3.7101 (3.7101)	loss 0.7322 (0.7322)	grad_norm 17.0391 (17.0391)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][10/146]	eta 0:01:53 lr 0.000001	 wd 0.0000	time 0.4022 (0.8372)	loss 0.7630 (0.7948)	grad_norm 7.2382 (14.0982)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:11 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][20/146]	eta 0:01:29 lr 0.000001	 wd 0.0000	time 0.4240 (0.7131)	loss 1.0122 (0.7975)	grad_norm 14.3500 (13.5063)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][30/146]	eta 0:01:15 lr 0.000001	 wd 0.0000	time 0.4347 (0.6506)	loss 0.7198 (0.8202)	grad_norm 6.9913 (13.7844)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 1.0857 (0.6597)	loss 0.5658 (0.8145)	grad_norm 9.0928 (13.1941)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][50/146]	eta 0:00:59 lr 0.000001	 wd 0.0000	time 0.4460 (0.6171)	loss 0.5531 (0.8122)	grad_norm 12.8437 (12.6496)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][60/146]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.7541 (0.6108)	loss 0.9725 (0.8177)	grad_norm 9.8059 (12.5216)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:39 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.9787 (0.6135)	loss 0.7014 (0.8194)	grad_norm 8.0101 (12.6680)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:44 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][80/146]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.4190 (0.5952)	loss 0.9291 (0.8102)	grad_norm 14.9985 (12.3889)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.4753 (0.5977)	loss 0.7417 (0.8141)	grad_norm 24.7510 (12.3688)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:46:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][100/146]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.3414 (0.5845)	loss 0.7048 (0.8111)	grad_norm 8.9824 (12.5712)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:00 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][110/146]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.3676 (0.5808)	loss 0.6495 (0.8028)	grad_norm 6.7085 (12.5095)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:05 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][120/146]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.4604 (0.5758)	loss 0.9332 (0.8091)	grad_norm 12.3975 (12.8651)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:10 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.3883 (0.5641)	loss 0.7306 (0.8083)	grad_norm 9.6329 (13.1284)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:15 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [23/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.5263 (0.5613)	loss 0.5264 (0.8071)	grad_norm 10.5653 (13.2216)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:16 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 23 training takes 0:01:20
[2026-01-19 10:47:24 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 7.835 (7.835)	Loss 0.0635 (0.0635)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:47:28 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.082 (1.113)	Loss 0.2881 (0.2458)	Acc@1 96.875 (94.034)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:47:29 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 91.111 Acc@5 0.000
[2026-01-19 10:47:29 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 91.1%
[2026-01-19 10:47:29 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:47:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][0/146]	eta 0:11:11 lr 0.000000	 wd 0.0000	time 4.6019 (4.6019)	loss 1.0565 (1.0565)	grad_norm 22.8253 (22.8253)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:38 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][10/146]	eta 0:01:52 lr 0.000000	 wd 0.0000	time 0.7418 (0.8292)	loss 0.7479 (0.7905)	grad_norm 6.2959 (16.3584)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][20/146]	eta 0:01:33 lr 0.000000	 wd 0.0000	time 0.3088 (0.7403)	loss 0.6571 (0.8060)	grad_norm 16.5828 (15.6463)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][30/146]	eta 0:01:18 lr 0.000000	 wd 0.0000	time 0.3730 (0.6742)	loss 0.8716 (0.8045)	grad_norm 6.2108 (13.9659)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:47:56 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][40/146]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 0.5558 (0.6447)	loss 1.0650 (0.8116)	grad_norm 14.3760 (14.6111)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][50/146]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 1.1149 (0.6300)	loss 0.9428 (0.8098)	grad_norm 14.3332 (14.3874)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][60/146]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 0.5673 (0.6200)	loss 0.9262 (0.8268)	grad_norm 7.5855 (14.7243)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:13 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][70/146]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.3331 (0.6171)	loss 0.7539 (0.8230)	grad_norm 11.1117 (14.3707)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:17 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][80/146]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.4340 (0.5897)	loss 1.0801 (0.8309)	grad_norm 14.3520 (14.2175)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.7316 (0.5910)	loss 0.9529 (0.8320)	grad_norm 7.4236 (13.8487)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:28 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][100/146]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.4590 (0.5837)	loss 0.6183 (0.8259)	grad_norm 10.5673 (13.5188)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:35 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.5334 (0.5913)	loss 0.8894 (0.8316)	grad_norm 7.7148 (13.3386)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:40 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.3373 (0.5833)	loss 0.7264 (0.8295)	grad_norm 14.3444 (13.1893)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:46 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.4394 (0.5871)	loss 0.6813 (0.8269)	grad_norm 11.2338 (13.4454)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [24/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2022 (0.5691)	loss 0.8140 (0.8235)	grad_norm 7.0079 (13.3239)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:48:51 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 24 training takes 0:01:21
[2026-01-19 10:49:00 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.150 (9.150)	Loss 0.0654 (0.0654)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:49:03 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.067 (1.115)	Loss 0.2927 (0.2498)	Acc@1 96.875 (94.034)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:49:04 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.940 Acc@5 0.000
[2026-01-19 10:49:04 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.9%
[2026-01-19 10:49:04 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:49:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][0/146]	eta 0:12:25 lr 0.000000	 wd 0.0000	time 5.1039 (5.1039)	loss 0.8402 (0.8402)	grad_norm 7.4134 (7.4134)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:16 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][10/146]	eta 0:02:26 lr 0.000000	 wd 0.0000	time 0.3639 (1.0757)	loss 0.9898 (0.8185)	grad_norm 11.9680 (14.6699)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][20/146]	eta 0:01:42 lr 0.000000	 wd 0.0000	time 0.3408 (0.8101)	loss 0.8434 (0.8416)	grad_norm 9.1184 (13.5135)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:27 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][30/146]	eta 0:01:26 lr 0.000000	 wd 0.0000	time 0.7255 (0.7455)	loss 0.9244 (0.8242)	grad_norm 12.5385 (12.8512)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][40/146]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 0.4420 (0.6884)	loss 0.6711 (0.8089)	grad_norm 6.0642 (12.1432)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:36 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][50/146]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 0.4552 (0.6342)	loss 0.8635 (0.8081)	grad_norm 10.4275 (12.8434)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][60/146]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 0.4382 (0.6257)	loss 0.6231 (0.8059)	grad_norm 6.6452 (12.8587)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][70/146]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.4414 (0.6168)	loss 0.7257 (0.8100)	grad_norm 12.2843 (13.0474)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][80/146]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.5775 (0.6101)	loss 0.8667 (0.8096)	grad_norm 27.1448 (13.1859)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:49:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.4330 (0.5980)	loss 0.9696 (0.8130)	grad_norm 20.2960 (12.9943)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][100/146]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.4130 (0.5821)	loss 0.6965 (0.8106)	grad_norm 9.5917 (12.9675)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.4301 (0.5879)	loss 0.9748 (0.8112)	grad_norm 17.8853 (13.2624)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.1332 (0.5820)	loss 0.6530 (0.8099)	grad_norm 6.5430 (13.1338)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.9684 (0.5846)	loss 0.7710 (0.8065)	grad_norm 13.9005 (13.1147)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [25/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.1997 (0.5665)	loss 0.5780 (0.8098)	grad_norm 15.1908 (12.9540)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:25 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 25 training takes 0:01:21
[2026-01-19 10:50:35 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.500 (9.500)	Loss 0.0637 (0.0637)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:50:38 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.072 (1.128)	Loss 0.2998 (0.2550)	Acc@1 96.875 (93.750)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:50:38 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.427 Acc@5 0.000
[2026-01-19 10:50:38 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.4%
[2026-01-19 10:50:38 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:50:44 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][0/146]	eta 0:13:50 lr 0.000000	 wd 0.0000	time 5.6870 (5.6870)	loss 0.9110 (0.9110)	grad_norm 17.2027 (17.2027)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:49 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][10/146]	eta 0:02:16 lr 0.000000	 wd 0.0000	time 0.3784 (1.0031)	loss 0.7663 (0.8238)	grad_norm 11.3771 (13.5846)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:50:55 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][20/146]	eta 0:01:36 lr 0.000000	 wd 0.0000	time 0.4874 (0.7693)	loss 0.9702 (0.8153)	grad_norm 8.1139 (14.6439)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:01 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][30/146]	eta 0:01:23 lr 0.000000	 wd 0.0000	time 0.4887 (0.7224)	loss 0.9423 (0.8283)	grad_norm 4.6739 (13.0995)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:06 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][40/146]	eta 0:01:10 lr 0.000000	 wd 0.0000	time 1.1397 (0.6688)	loss 0.9277 (0.8389)	grad_norm 12.2207 (13.6950)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:12 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][50/146]	eta 0:01:02 lr 0.000000	 wd 0.0000	time 0.6155 (0.6498)	loss 0.9027 (0.8234)	grad_norm 7.7714 (12.9575)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:18 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][60/146]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 0.4171 (0.6490)	loss 0.7313 (0.8260)	grad_norm 8.9644 (12.6466)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:23 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][70/146]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 0.3949 (0.6237)	loss 0.7133 (0.8128)	grad_norm 8.9305 (12.5983)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:29 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][80/146]	eta 0:00:41 lr 0.000000	 wd 0.0000	time 0.8597 (0.6261)	loss 0.5690 (0.8064)	grad_norm 12.6662 (12.4577)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:34 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.4606 (0.6062)	loss 0.6650 (0.8067)	grad_norm 11.2801 (12.7810)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:40 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][100/146]	eta 0:00:28 lr 0.000000	 wd 0.0000	time 0.3191 (0.6130)	loss 0.7897 (0.8051)	grad_norm 7.2757 (12.7401)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:45 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.3617 (0.6004)	loss 0.8114 (0.8004)	grad_norm 12.1003 (12.5826)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:50 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.5857 (0.5896)	loss 0.7674 (0.8047)	grad_norm 11.9900 (12.5084)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:56 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.4387 (0.5908)	loss 0.8292 (0.8052)	grad_norm 10.7320 (12.7428)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:51:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [26/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2156 (0.5718)	loss 0.6421 (0.8073)	grad_norm 63.5718 (13.0911)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:00 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 26 training takes 0:01:21
[2026-01-19 10:52:09 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.871 (8.871)	Loss 0.0647 (0.0647)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:52:13 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.069 (1.129)	Loss 0.2983 (0.2540)	Acc@1 96.875 (93.750)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:52:13 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.427 Acc@5 0.000
[2026-01-19 10:52:13 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.4%
[2026-01-19 10:52:13 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:52:20 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][0/146]	eta 0:15:27 lr 0.000000	 wd 0.0000	time 6.3522 (6.3522)	loss 0.8407 (0.8407)	grad_norm 16.9475 (16.9475)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:24 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][10/146]	eta 0:02:14 lr 0.000000	 wd 0.0000	time 0.4684 (0.9920)	loss 1.0010 (0.7866)	grad_norm 10.0653 (15.8924)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][20/146]	eta 0:01:39 lr 0.000000	 wd 0.0000	time 0.4415 (0.7897)	loss 0.8542 (0.8108)	grad_norm 7.5806 (14.2921)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:36 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][30/146]	eta 0:01:24 lr 0.000000	 wd 0.0000	time 0.4291 (0.7302)	loss 0.9109 (0.8474)	grad_norm 11.1775 (15.0780)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][40/146]	eta 0:01:14 lr 0.000000	 wd 0.0000	time 2.0110 (0.7031)	loss 0.8741 (0.8403)	grad_norm 12.0663 (14.8350)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][50/146]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 0.4010 (0.6814)	loss 0.7065 (0.8312)	grad_norm 10.2174 (14.6283)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][60/146]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 0.3787 (0.6443)	loss 0.6612 (0.8220)	grad_norm 17.7793 (14.4017)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:52:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][70/146]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 0.8127 (0.6325)	loss 0.9829 (0.8152)	grad_norm 11.6252 (14.7964)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][80/146]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.4424 (0.6110)	loss 0.9406 (0.8165)	grad_norm 7.6195 (14.2146)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 1.4331 (0.6029)	loss 0.9617 (0.8134)	grad_norm 7.7401 (13.8729)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.4491 (0.6036)	loss 0.8110 (0.8148)	grad_norm 12.6666 (13.9253)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:19 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.4943 (0.5876)	loss 0.9971 (0.8266)	grad_norm 6.3884 (13.7946)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 2.3752 (0.5914)	loss 1.3944 (0.8263)	grad_norm 30.4270 (14.0078)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:30 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.4608 (0.5873)	loss 0.7747 (0.8171)	grad_norm 14.2306 (14.0330)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:33 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [27/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2057 (0.5666)	loss 0.6306 (0.8138)	grad_norm 15.6337 (14.0305)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:35 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 27 training takes 0:01:21
[2026-01-19 10:53:43 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.801 (8.801)	Loss 0.0656 (0.0656)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:53:47 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.070 (1.091)	Loss 0.2983 (0.2540)	Acc@1 96.875 (94.034)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:53:48 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.769 Acc@5 0.000
[2026-01-19 10:53:48 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.8%
[2026-01-19 10:53:48 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:53:54 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][0/146]	eta 0:14:34 lr 0.000000	 wd 0.0000	time 5.9896 (5.9896)	loss 0.7457 (0.7457)	grad_norm 8.3796 (8.3796)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:53:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][10/146]	eta 0:02:12 lr 0.000000	 wd 0.0000	time 0.4382 (0.9760)	loss 0.5966 (0.7868)	grad_norm 7.6722 (11.1948)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:03 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][20/146]	eta 0:01:35 lr 0.000000	 wd 0.0000	time 0.7812 (0.7549)	loss 0.8033 (0.7843)	grad_norm 19.3869 (12.6169)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:08 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][30/146]	eta 0:01:17 lr 0.000000	 wd 0.0000	time 0.3884 (0.6663)	loss 0.9771 (0.8132)	grad_norm 17.0167 (12.1457)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][40/146]	eta 0:01:07 lr 0.000000	 wd 0.0000	time 0.3881 (0.6374)	loss 0.9757 (0.8285)	grad_norm 12.6698 (12.4661)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:20 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][50/146]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 0.3674 (0.6328)	loss 0.8687 (0.8186)	grad_norm 13.1520 (12.1573)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][60/146]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 0.4874 (0.6181)	loss 0.7679 (0.8056)	grad_norm 7.4387 (12.8435)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:32 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][70/146]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 1.5158 (0.6237)	loss 0.7361 (0.8159)	grad_norm 14.2223 (13.1333)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][80/146]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.4366 (0.6057)	loss 0.9726 (0.8209)	grad_norm 21.4564 (13.3094)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.4215 (0.5973)	loss 0.8016 (0.8244)	grad_norm 8.4937 (13.3761)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:48 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.3660 (0.6008)	loss 0.8999 (0.8256)	grad_norm 12.6725 (13.2201)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.3406 (0.5863)	loss 0.9024 (0.8215)	grad_norm 7.4247 (13.5579)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:54:59 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.6036 (0.5875)	loss 0.8385 (0.8185)	grad_norm 5.3850 (13.2053)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:04 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.4127 (0.5815)	loss 1.0324 (0.8230)	grad_norm 33.6593 (13.3546)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:07 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [28/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2043 (0.5634)	loss 0.5248 (0.8202)	grad_norm 7.2188 (13.2257)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:08 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 28 training takes 0:01:20
[2026-01-19 10:55:17 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 9.066 (9.066)	Loss 0.0651 (0.0651)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:55:20 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.072 (1.093)	Loss 0.3003 (0.2554)	Acc@1 96.875 (93.750)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:55:21 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.427 Acc@5 0.000
[2026-01-19 10:55:21 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.4%
[2026-01-19 10:55:21 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:55:26 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][0/146]	eta 0:12:15 lr 0.000000	 wd 0.0000	time 5.0381 (5.0381)	loss 0.6602 (0.6602)	grad_norm 13.9634 (13.9634)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:31 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][10/146]	eta 0:02:05 lr 0.000000	 wd 0.0000	time 1.1660 (0.9255)	loss 0.6418 (0.7634)	grad_norm 13.9542 (11.3113)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][20/146]	eta 0:01:33 lr 0.000000	 wd 0.0000	time 0.6353 (0.7411)	loss 0.7065 (0.7917)	grad_norm 16.2055 (14.4367)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:42 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][30/146]	eta 0:01:17 lr 0.000000	 wd 0.0000	time 0.4145 (0.6679)	loss 0.9008 (0.7942)	grad_norm 9.9627 (14.0092)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:47 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][40/146]	eta 0:01:06 lr 0.000000	 wd 0.0000	time 0.4451 (0.6237)	loss 0.8609 (0.7821)	grad_norm 12.0254 (12.9842)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:53 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][50/146]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 0.9957 (0.6330)	loss 0.7913 (0.7855)	grad_norm 9.5398 (13.6610)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:55:58 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][60/146]	eta 0:00:52 lr 0.000000	 wd 0.0000	time 0.4445 (0.6064)	loss 0.8578 (0.7922)	grad_norm 7.1500 (14.6762)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:04 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][70/146]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.6781 (0.6091)	loss 0.7641 (0.7866)	grad_norm 13.3396 (14.7371)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:09 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][80/146]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.3767 (0.5871)	loss 0.7563 (0.7930)	grad_norm 8.7538 (14.2785)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:14 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][90/146]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 1.2181 (0.5856)	loss 0.6700 (0.7984)	grad_norm 5.8548 (14.1257)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:21 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.4503 (0.5881)	loss 0.7689 (0.7968)	grad_norm 13.9116 (13.8445)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:25 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][110/146]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.3606 (0.5758)	loss 0.8028 (0.7955)	grad_norm 13.4642 (13.7808)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:31 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.5532 (0.5810)	loss 0.8299 (0.7975)	grad_norm 10.0683 (13.5782)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:37 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.3151 (0.5784)	loss 1.1274 (0.7996)	grad_norm 10.2042 (13.4647)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:40 swin_tiny_patch4_window7_224] (main.py 234): INFO Train: [29/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2014 (0.5614)	loss 0.7350 (0.8020)	grad_norm 12.5198 (13.3442)	loss_scale 8192.0000 (8192.0000)	mem 2679MB
[2026-01-19 10:56:42 swin_tiny_patch4_window7_224] (main.py 243): INFO EPOCH 29 training takes 0:01:20
[2026-01-19 10:56:50 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [0/19]	Time 8.613 (8.613)	Loss 0.0653 (0.0653)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:56:53 swin_tiny_patch4_window7_224] (main.py 287): INFO Test: [10/19]	Time 0.073 (1.057)	Loss 0.2998 (0.2550)	Acc@1 96.875 (93.750)	Acc@5 0.000 (0.000)	Mem 2679MB
[2026-01-19 10:56:54 swin_tiny_patch4_window7_224] (main.py 294): INFO  * Acc@1 90.427 Acc@5 0.000
[2026-01-19 10:56:54 swin_tiny_patch4_window7_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 90.4%
[2026-01-19 10:56:54 swin_tiny_patch4_window7_224] (main.py 179): INFO Max accuracy: 91.11%
[2026-01-19 10:56:54 swin_tiny_patch4_window7_224] (main.py 183): INFO Training time 0:47:15
