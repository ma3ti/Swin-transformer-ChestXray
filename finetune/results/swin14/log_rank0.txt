[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 364): INFO Full config saved to output/swin_tiny_window14_224/default/config.json
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 367): INFO AMP_ENABLE: true
AMP_OPT_LEVEL: ''
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: custom
  DATA_PATH: /content/dataset/chest_xray_new
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  MASK_PATCH_SIZE: 32
  MASK_RATIO: 0.6
  NUM_WORKERS: 8
  PIN_MEMORY: true
  ZIP_MODE: false
ENABLE_AMP: false
EVAL_MODE: false
FUSED_LAYERNORM: false
FUSED_WINDOW_PROCESS: false
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.2
  DROP_RATE: 0.0
  LABEL_SMOOTHING: 0.1
  NAME: swin_tiny_window14_224
  NUM_CLASSES: 2
  PRETRAINED: /content/swin_tiny_patch4_window7_224.pth
  RESUME: ''
  SIMMIM:
    NORM_TARGET:
      ENABLE: false
      PATCH_SIZE: 47
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 14
  SWINV2:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    WINDOW_SIZE: 7
  SWIN_MLP:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    WINDOW_SIZE: 7
  SWIN_MOE:
    APE: false
    AUX_LOSS_WEIGHT: 0.01
    CAPACITY_FACTOR: 1.25
    COSINE_ROUTER: false
    COSINE_ROUTER_DIM: 256
    COSINE_ROUTER_INIT_T: 0.5
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    GATE_NOISE: 1.0
    INIT_STD: 0.02
    IN_CHANS: 3
    IS_GSHARD_LOSS: false
    MLP_FC2_BIAS: true
    MLP_RATIO: 4.0
    MOE_BLOCKS:
    - - -1
    - - -1
    - - -1
    - - -1
    MOE_DROP: 0.0
    NORMALIZE_GATE: false
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    NUM_LOCAL_EXPERTS: 1
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAINED_WINDOW_SIZES:
    - 0
    - 0
    - 0
    - 0
    QKV_BIAS: true
    QK_SCALE: null
    TOP_VALUE: 1
    USE_BPR: true
    WINDOW_SIZE: 7
  TYPE: swin
OUTPUT: output/swin_tiny_window14_224/default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: true
  SEQUENTIAL: false
  SHUFFLE: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 3.125e-06
  CLIP_GRAD: 5.0
  EPOCHS: 30
  LAYER_DECAY: 1.0
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
    WARMUP_PREFIX: true
  MIN_LR: 6.25e-09
  MOE:
    SAVE_MASTER: false
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 3.125e-08
  WEIGHT_DECAY: 1.0e-08

[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 368): INFO {"cfg": "configs/swin/chest_xray_window14.yaml", "opts": ["MODEL.NUM_CLASSES", "2"], "batch_size": 32, "data_path": "/content/dataset/chest_xray_new", "zip": false, "cache_mode": "part", "pretrained": "/content/swin_tiny_patch4_window7_224.pth", "resume": null, "accumulation_steps": 1, "use_checkpoint": false, "disable_amp": false, "amp_opt_level": null, "output": "output", "tag": null, "eval": false, "throughput": false, "fused_window_process": false, "fused_layernorm": false, "optim": null}
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 94): INFO Creating model:swin/swin_tiny_window14_224
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 96): INFO SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=(56, 56), num_heads=3, window_size=14, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(14, 14), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=(56, 56), num_heads=3, window_size=14, shift_size=7, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(14, 14), num_heads=3
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=96
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=192, input_resolution=(28, 28), num_heads=6, window_size=14, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(14, 14), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=192, input_resolution=(28, 28), num_heads=6, window_size=14, shift_size=7, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(14, 14), num_heads=6
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=192
        (reduction): Linear(in_features=768, out_features=384, bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=384, input_resolution=(14, 14), depth=6
      (blocks): ModuleList(
        (0-5): 6 x SwinTransformerBlock(
          dim=384, input_resolution=(14, 14), num_heads=12, window_size=14, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(14, 14), num_heads=12
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=384
        (reduction): Linear(in_features=1536, out_features=768, bias=False)
        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=768, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(7, 7), num_heads=24
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=768, out_features=2, bias=True)
)
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 99): INFO number of params: 27571292
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 102): INFO number of GFLOPs: 4.891935744
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 126): INFO USING WEIGHTED LOSS: [Normal: 3.0, Pneumonia: 1.0]
[2026-01-19 16:53:09 swin_tiny_window14_224] (main.py 140): INFO no checkpoint found in output/swin_tiny_window14_224/default, ignoring auto resume
[2026-01-19 16:53:09 swin_tiny_window14_224] (utils.py 46): INFO ==============> Loading weight /content/swin_tiny_patch4_window7_224.pth for fine-tuning......
[2026-01-19 16:53:10 swin_tiny_window14_224] (utils.py 125): WARNING Error in loading classifier head, re-init classifier head to 0
[2026-01-19 16:53:10 swin_tiny_window14_224] (utils.py 128): WARNING _IncompatibleKeys(missing_keys=['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index', 'head.weight', 'head.bias'], unexpected_keys=[])
[2026-01-19 16:53:10 swin_tiny_window14_224] (utils.py 130): INFO => loaded successfully '/content/swin_tiny_patch4_window7_224.pth'
[2026-01-19 16:53:20 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 10.288 (10.288)	Loss 0.6934 (0.6934)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 956MB
[2026-01-19 16:53:22 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.092 (1.147)	Loss 0.6934 (0.6934)	Acc@1 0.000 (44.886)	Acc@5 0.000 (0.000)	Mem 956MB
[2026-01-19 16:53:23 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 27.009 Acc@5 0.000
[2026-01-19 16:53:23 swin_tiny_window14_224] (main.py 152): INFO Accuracy of the network on the 585 test images: 27.0%
[2026-01-19 16:53:23 swin_tiny_window14_224] (main.py 158): INFO Start training
[2026-01-19 16:53:30 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][0/146]	eta 0:14:56 lr 0.000000	 wd 0.0000	time 6.1376 (6.1376)	loss 0.9577 (0.9577)	grad_norm 2.9636 (2.9636)	loss_scale 65536.0000 (65536.0000)	mem 3610MB
[2026-01-19 16:53:34 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][10/146]	eta 0:02:12 lr 0.000000	 wd 0.0000	time 0.6607 (0.9748)	loss 0.9965 (1.0818)	grad_norm 2.2772 (3.0041)	loss_scale 65536.0000 (65536.0000)	mem 3825MB
[2026-01-19 16:53:39 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][20/146]	eta 0:01:34 lr 0.000000	 wd 0.0000	time 0.4134 (0.7514)	loss 1.0353 (1.1098)	grad_norm 1.9450 (3.4414)	loss_scale 65536.0000 (65536.0000)	mem 3825MB
[2026-01-19 16:53:44 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][30/146]	eta 0:01:16 lr 0.000000	 wd 0.0000	time 0.4009 (0.6578)	loss 1.1522 (1.0971)	grad_norm 4.4046 (inf)	loss_scale 32768.0000 (54965.6774)	mem 3825MB
[2026-01-19 16:53:49 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][40/146]	eta 0:01:06 lr 0.000000	 wd 0.0000	time 0.6655 (0.6288)	loss 1.0353 (1.0925)	grad_norm 2.0430 (inf)	loss_scale 32768.0000 (49551.6098)	mem 3825MB
[2026-01-19 16:53:55 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][50/146]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 0.4214 (0.6112)	loss 1.1132 (1.0996)	grad_norm 3.2674 (inf)	loss_scale 32768.0000 (46260.7059)	mem 3825MB
[2026-01-19 16:54:00 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][60/146]	eta 0:00:51 lr 0.000000	 wd 0.0000	time 0.6259 (0.5962)	loss 1.0743 (1.1018)	grad_norm 2.4047 (inf)	loss_scale 32768.0000 (44048.7869)	mem 3825MB
[2026-01-19 16:54:06 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][70/146]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.3345 (0.6036)	loss 1.1906 (1.1056)	grad_norm 5.5837 (inf)	loss_scale 32768.0000 (42459.9437)	mem 3825MB
[2026-01-19 16:54:11 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][80/146]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.4523 (0.5902)	loss 1.2680 (1.1017)	grad_norm 6.9348 (inf)	loss_scale 32768.0000 (41263.4074)	mem 3825MB
[2026-01-19 16:54:17 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][90/146]	eta 0:00:32 lr 0.000000	 wd 0.0000	time 0.4121 (0.5855)	loss 1.0353 (1.0961)	grad_norm 1.9628 (inf)	loss_scale 32768.0000 (40329.8462)	mem 3825MB
[2026-01-19 16:54:22 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][100/146]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.4710 (0.5827)	loss 1.1126 (1.1008)	grad_norm 4.1023 (inf)	loss_scale 32768.0000 (39581.1485)	mem 3825MB
[2026-01-19 16:54:29 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.6365 (0.5879)	loss 1.1124 (1.0991)	grad_norm 3.8321 (inf)	loss_scale 32768.0000 (38967.3514)	mem 3825MB
[2026-01-19 16:54:35 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 1.2079 (0.5902)	loss 1.1509 (1.0989)	grad_norm 4.4760 (inf)	loss_scale 32768.0000 (38455.0083)	mem 3825MB
[2026-01-19 16:54:40 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.6207 (0.5876)	loss 0.9581 (1.1002)	grad_norm 2.4528 (inf)	loss_scale 32768.0000 (38020.8855)	mem 3825MB
[2026-01-19 16:54:44 swin_tiny_window14_224] (main.py 234): INFO Train: [0/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2606 (0.5706)	loss 0.9970 (1.1005)	grad_norm 3.3288 (inf)	loss_scale 32768.0000 (37648.3404)	mem 3825MB
[2026-01-19 16:54:45 swin_tiny_window14_224] (main.py 243): INFO EPOCH 0 training takes 0:01:21
[2026-01-19 16:54:55 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.422 (9.422)	Loss 0.6841 (0.6841)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:54:58 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.093 (1.148)	Loss 0.7002 (0.6929)	Acc@1 0.000 (44.886)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:54:59 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 27.009 Acc@5 0.000
[2026-01-19 16:54:59 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 27.0%
[2026-01-19 16:54:59 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_0.pth saving......
[2026-01-19 16:55:00 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_0.pth saved !!!
[2026-01-19 16:55:00 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 0): 27.01% ***
[2026-01-19 16:55:00 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 27.01%
[2026-01-19 16:55:05 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][0/146]	eta 0:10:43 lr 0.000001	 wd 0.0000	time 4.4100 (4.4100)	loss 1.1110 (1.1110)	grad_norm 3.9493 (3.9493)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:11 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][10/146]	eta 0:02:12 lr 0.000001	 wd 0.0000	time 0.4379 (0.9767)	loss 0.9964 (1.0934)	grad_norm 3.3392 (4.1622)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:16 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][20/146]	eta 0:01:35 lr 0.000001	 wd 0.0000	time 0.4371 (0.7544)	loss 0.9586 (1.0764)	grad_norm 3.4742 (3.8344)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:22 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][30/146]	eta 0:01:21 lr 0.000001	 wd 0.0000	time 0.3525 (0.7064)	loss 1.2241 (1.1008)	grad_norm 6.4506 (4.3429)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:27 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.4498 (0.6588)	loss 1.1092 (1.0983)	grad_norm 4.3135 (4.4133)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:33 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][50/146]	eta 0:01:01 lr 0.000001	 wd 0.0000	time 0.7625 (0.6454)	loss 1.1444 (1.1078)	grad_norm 6.6311 (4.6478)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:38 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][60/146]	eta 0:00:53 lr 0.000001	 wd 0.0000	time 0.4228 (0.6242)	loss 1.0323 (1.0999)	grad_norm 3.8309 (4.5853)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:43 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.4302 (0.6065)	loss 1.0730 (1.0937)	grad_norm 2.4969 (4.4662)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:50 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 0.7121 (0.6091)	loss 1.0688 (1.0948)	grad_norm 3.9356 (4.5917)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:55:56 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][90/146]	eta 0:00:34 lr 0.000001	 wd 0.0000	time 0.3211 (0.6117)	loss 1.3244 (1.0964)	grad_norm 12.2703 (4.7201)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:02 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][100/146]	eta 0:00:28 lr 0.000001	 wd 0.0000	time 0.2975 (0.6147)	loss 1.1423 (1.1009)	grad_norm 4.8940 (4.8958)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:07 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.3377 (0.6001)	loss 0.9922 (1.1000)	grad_norm 4.1775 (4.9986)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:11 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.5956 (0.5874)	loss 0.9901 (1.0981)	grad_norm 5.0346 (5.0011)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:17 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.4247 (0.5856)	loss 1.0015 (1.0954)	grad_norm 4.0511 (5.0545)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:20 swin_tiny_window14_224] (main.py 234): INFO Train: [1/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2782 (0.5693)	loss 1.1688 (1.0937)	grad_norm 8.4956 (5.1130)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:22 swin_tiny_window14_224] (main.py 243): INFO EPOCH 1 training takes 0:01:21
[2026-01-19 16:56:31 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.286 (9.286)	Loss 0.6143 (0.6143)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:56:34 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.129)	Loss 0.7402 (0.6861)	Acc@1 0.000 (44.886)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:56:35 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 27.179 Acc@5 0.000
[2026-01-19 16:56:35 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 27.2%
[2026-01-19 16:56:35 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_1.pth saving......
[2026-01-19 16:56:36 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_1.pth saved !!!
[2026-01-19 16:56:36 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 1): 27.18% ***
[2026-01-19 16:56:36 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 27.18%
[2026-01-19 16:56:42 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][0/146]	eta 0:14:00 lr 0.000001	 wd 0.0000	time 5.7537 (5.7537)	loss 1.0603 (1.0603)	grad_norm 5.0384 (5.0384)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:48 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][10/146]	eta 0:02:21 lr 0.000001	 wd 0.0000	time 1.2673 (1.0372)	loss 1.1349 (1.0603)	grad_norm 7.1971 (7.1271)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:54 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][20/146]	eta 0:01:46 lr 0.000001	 wd 0.0000	time 0.4383 (0.8462)	loss 1.0276 (1.0738)	grad_norm 3.2921 (6.8372)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:56:59 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][30/146]	eta 0:01:26 lr 0.000001	 wd 0.0000	time 0.4031 (0.7418)	loss 1.2529 (1.0857)	grad_norm 14.4940 (7.0341)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:04 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][40/146]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.6330 (0.6697)	loss 1.1177 (1.0788)	grad_norm 8.1461 (7.1400)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:09 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][50/146]	eta 0:01:02 lr 0.000001	 wd 0.0000	time 0.3810 (0.6524)	loss 1.0175 (1.0729)	grad_norm 4.6140 (6.9089)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:15 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][60/146]	eta 0:00:54 lr 0.000002	 wd 0.0000	time 0.4248 (0.6316)	loss 1.0548 (1.0742)	grad_norm 5.9550 (6.9107)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:21 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][70/146]	eta 0:00:47 lr 0.000002	 wd 0.0000	time 0.4495 (0.6248)	loss 1.1852 (1.0758)	grad_norm 9.7364 (7.0172)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:26 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][80/146]	eta 0:00:40 lr 0.000002	 wd 0.0000	time 1.3429 (0.6171)	loss 1.0319 (1.0763)	grad_norm 3.1751 (7.1733)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:31 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.7596 (0.6069)	loss 0.9896 (1.0750)	grad_norm 5.2930 (7.2199)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:37 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.4289 (0.6067)	loss 1.1373 (1.0747)	grad_norm 8.3344 (7.3270)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:43 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.4304 (0.5981)	loss 1.1003 (1.0741)	grad_norm 10.0703 (7.2333)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:49 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 1.3398 (0.6012)	loss 1.1514 (1.0759)	grad_norm 10.5587 (7.3624)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:54 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4627 (0.5938)	loss 0.9118 (1.0739)	grad_norm 6.5318 (7.3899)	loss_scale 32768.0000 (32768.0000)	mem 3825MB
[2026-01-19 16:57:58 swin_tiny_window14_224] (main.py 234): INFO Train: [2/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2636 (0.5789)	loss 0.9560 (1.0722)	grad_norm 4.0042 (inf)	loss_scale 16384.0000 (31838.4113)	mem 3825MB
[2026-01-19 16:57:59 swin_tiny_window14_224] (main.py 243): INFO EPOCH 2 training takes 0:01:23
[2026-01-19 16:58:07 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 7.753 (7.753)	Loss 0.4585 (0.4585)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:58:12 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.098 (1.118)	Loss 0.7744 (0.6576)	Acc@1 6.250 (47.159)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:58:12 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 32.479 Acc@5 0.000
[2026-01-19 16:58:12 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 32.5%
[2026-01-19 16:58:12 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_2.pth saving......
[2026-01-19 16:58:13 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_2.pth saved !!!
[2026-01-19 16:58:14 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 2): 32.48% ***
[2026-01-19 16:58:14 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 32.48%
[2026-01-19 16:58:19 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][0/146]	eta 0:12:17 lr 0.000002	 wd 0.0000	time 5.0536 (5.0536)	loss 1.0741 (1.0741)	grad_norm 4.8862 (4.8862)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:25 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][10/146]	eta 0:02:20 lr 0.000002	 wd 0.0000	time 0.3893 (1.0340)	loss 1.0671 (1.0626)	grad_norm 5.3690 (9.2923)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:31 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][20/146]	eta 0:01:42 lr 0.000002	 wd 0.0000	time 0.3744 (0.8113)	loss 0.9540 (1.0330)	grad_norm 8.8447 (8.6631)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:36 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][30/146]	eta 0:01:22 lr 0.000002	 wd 0.0000	time 0.6896 (0.7110)	loss 1.0374 (1.0402)	grad_norm 14.5564 (9.1454)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:42 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][40/146]	eta 0:01:13 lr 0.000002	 wd 0.0000	time 0.7403 (0.6927)	loss 1.0553 (1.0427)	grad_norm 9.4415 (8.7963)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:47 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][50/146]	eta 0:01:02 lr 0.000002	 wd 0.0000	time 0.4337 (0.6558)	loss 0.9849 (1.0463)	grad_norm 7.8946 (8.7348)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:52 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][60/146]	eta 0:00:54 lr 0.000002	 wd 0.0000	time 0.4548 (0.6380)	loss 0.9711 (1.0383)	grad_norm 10.2445 (8.5307)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:58:58 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][70/146]	eta 0:00:47 lr 0.000002	 wd 0.0000	time 0.4227 (0.6208)	loss 0.9784 (1.0386)	grad_norm 6.8378 (8.9154)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:04 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][80/146]	eta 0:00:41 lr 0.000002	 wd 0.0000	time 1.4629 (0.6252)	loss 0.9595 (1.0358)	grad_norm 11.7536 (8.7255)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:09 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][90/146]	eta 0:00:34 lr 0.000002	 wd 0.0000	time 0.3957 (0.6097)	loss 1.0581 (1.0331)	grad_norm 9.6464 (8.7466)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:15 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.6983 (0.6069)	loss 1.0914 (1.0316)	grad_norm 9.4451 (8.7301)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:20 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.4313 (0.6012)	loss 0.9183 (1.0279)	grad_norm 5.3845 (8.6075)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:25 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.7350 (0.5903)	loss 1.0174 (1.0266)	grad_norm 6.6720 (8.5584)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:31 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.3632 (0.5916)	loss 0.9090 (1.0232)	grad_norm 7.4023 (8.5241)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:34 swin_tiny_window14_224] (main.py 234): INFO Train: [3/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2622 (0.5721)	loss 1.1045 (1.0236)	grad_norm 6.4933 (8.4947)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 16:59:36 swin_tiny_window14_224] (main.py 243): INFO EPOCH 3 training takes 0:01:22
[2026-01-19 16:59:45 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.010 (9.010)	Loss 0.2913 (0.2913)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:59:48 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.120)	Loss 0.7070 (0.5795)	Acc@1 75.000 (75.284)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 16:59:49 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 69.402 Acc@5 0.000
[2026-01-19 16:59:49 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 69.4%
[2026-01-19 16:59:49 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_3.pth saving......
[2026-01-19 16:59:50 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_3.pth saved !!!
[2026-01-19 16:59:50 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 3): 69.40% ***
[2026-01-19 16:59:50 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 69.40%
[2026-01-19 16:59:56 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][0/146]	eta 0:15:17 lr 0.000003	 wd 0.0000	time 6.2866 (6.2866)	loss 0.9882 (0.9882)	grad_norm 6.3166 (6.3166)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:01 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][10/146]	eta 0:02:20 lr 0.000003	 wd 0.0000	time 0.7059 (1.0332)	loss 0.9538 (1.0392)	grad_norm 8.5129 (8.8183)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:06 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][20/146]	eta 0:01:37 lr 0.000003	 wd 0.0000	time 0.4184 (0.7703)	loss 1.1175 (1.0253)	grad_norm 8.4009 (9.8860)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:12 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][30/146]	eta 0:01:23 lr 0.000003	 wd 0.0000	time 0.4436 (0.7227)	loss 0.9389 (1.0034)	grad_norm 4.1289 (9.6060)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:18 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][40/146]	eta 0:01:12 lr 0.000003	 wd 0.0000	time 1.2647 (0.6836)	loss 1.1386 (1.0052)	grad_norm 9.0165 (9.6227)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:24 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][50/146]	eta 0:01:04 lr 0.000003	 wd 0.0000	time 0.4275 (0.6727)	loss 0.9025 (1.0006)	grad_norm 8.8732 (9.5497)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:29 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][60/146]	eta 0:00:54 lr 0.000003	 wd 0.0000	time 0.3233 (0.6392)	loss 0.9693 (0.9948)	grad_norm 11.5350 (9.9889)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:35 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][70/146]	eta 0:00:48 lr 0.000003	 wd 0.0000	time 0.6197 (0.6332)	loss 0.9686 (0.9933)	grad_norm 16.5431 (9.9540)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:39 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 0.5590 (0.6096)	loss 1.0393 (0.9856)	grad_norm 8.4871 (9.9357)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:44 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.3598 (0.5939)	loss 1.0185 (0.9888)	grad_norm 9.5897 (9.9406)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:50 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.4189 (0.5941)	loss 0.9014 (0.9843)	grad_norm 16.2677 (10.1383)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:00:54 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.3799 (0.5791)	loss 0.9431 (0.9814)	grad_norm 7.7573 (10.3315)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:00 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.7527 (0.5806)	loss 0.9331 (0.9775)	grad_norm 15.3497 (10.4908)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:06 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.3549 (0.5776)	loss 0.9944 (0.9720)	grad_norm 4.8499 (10.6113)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:09 swin_tiny_window14_224] (main.py 234): INFO Train: [4/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2663 (0.5629)	loss 0.9342 (0.9688)	grad_norm 6.2917 (10.5700)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:11 swin_tiny_window14_224] (main.py 243): INFO EPOCH 4 training takes 0:01:20
[2026-01-19 17:01:20 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.161 (9.161)	Loss 0.1998 (0.1998)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:01:23 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.093 (1.125)	Loss 0.5498 (0.4778)	Acc@1 93.750 (86.080)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:01:24 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 82.906 Acc@5 0.000
[2026-01-19 17:01:24 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 82.9%
[2026-01-19 17:01:24 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_4.pth saving......
[2026-01-19 17:01:25 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_4.pth saved !!!
[2026-01-19 17:01:25 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 4): 82.91% ***
[2026-01-19 17:01:25 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 82.91%
[2026-01-19 17:01:31 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][0/146]	eta 0:13:56 lr 0.000003	 wd 0.0000	time 5.7290 (5.7290)	loss 0.9681 (0.9681)	grad_norm 11.1269 (11.1269)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:35 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][10/146]	eta 0:02:01 lr 0.000003	 wd 0.0000	time 0.4048 (0.8906)	loss 0.9092 (0.9904)	grad_norm 9.9487 (13.9584)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:41 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][20/146]	eta 0:01:38 lr 0.000003	 wd 0.0000	time 0.4406 (0.7800)	loss 0.9662 (0.9611)	grad_norm 7.1153 (12.9706)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:46 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][30/146]	eta 0:01:20 lr 0.000003	 wd 0.0000	time 0.4730 (0.6923)	loss 1.0161 (0.9486)	grad_norm 13.3720 (12.8988)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:53 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][40/146]	eta 0:01:11 lr 0.000003	 wd 0.0000	time 0.5888 (0.6739)	loss 0.9404 (0.9482)	grad_norm 9.7437 (13.2102)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:01:57 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][50/146]	eta 0:01:00 lr 0.000003	 wd 0.0000	time 0.4283 (0.6252)	loss 0.9454 (0.9441)	grad_norm 23.7045 (13.8816)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:03 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][60/146]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.4062 (0.6228)	loss 1.0326 (0.9410)	grad_norm 14.0057 (13.5745)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:09 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][70/146]	eta 0:00:47 lr 0.000003	 wd 0.0000	time 0.4590 (0.6237)	loss 1.1344 (0.9436)	grad_norm 21.2092 (13.4875)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:14 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][80/146]	eta 0:00:39 lr 0.000003	 wd 0.0000	time 0.4027 (0.6056)	loss 0.8159 (0.9287)	grad_norm 19.0738 (13.4608)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:20 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.4501 (0.6005)	loss 1.0747 (0.9304)	grad_norm 13.4247 (13.5030)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:25 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.3975 (0.5903)	loss 0.8051 (0.9322)	grad_norm 10.5399 (13.6373)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:29 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][110/146]	eta 0:00:20 lr 0.000003	 wd 0.0000	time 0.4026 (0.5759)	loss 0.7692 (0.9292)	grad_norm 15.4835 (13.7994)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:35 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][120/146]	eta 0:00:14 lr 0.000003	 wd 0.0000	time 0.4346 (0.5768)	loss 0.9316 (0.9245)	grad_norm 7.5507 (13.8030)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:40 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.3813 (0.5706)	loss 0.8000 (0.9247)	grad_norm 10.0493 (13.9847)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:44 swin_tiny_window14_224] (main.py 234): INFO Train: [5/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2700 (0.5639)	loss 0.8801 (0.9264)	grad_norm 11.9923 (14.4094)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:02:46 swin_tiny_window14_224] (main.py 243): INFO EPOCH 5 training takes 0:01:20
[2026-01-19 17:02:54 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 7.859 (7.859)	Loss 0.1534 (0.1534)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:02:58 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.116 (1.117)	Loss 0.3582 (0.3758)	Acc@1 96.875 (89.489)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:02:59 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 85.641 Acc@5 0.000
[2026-01-19 17:02:59 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.6%
[2026-01-19 17:02:59 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_5.pth saving......
[2026-01-19 17:03:00 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_5.pth saved !!!
[2026-01-19 17:03:00 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 5): 85.64% ***
[2026-01-19 17:03:00 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 85.64%
[2026-01-19 17:03:04 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][0/146]	eta 0:10:22 lr 0.000003	 wd 0.0000	time 4.2670 (4.2670)	loss 0.7924 (0.7924)	grad_norm 17.7558 (17.7558)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:10 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][10/146]	eta 0:02:08 lr 0.000003	 wd 0.0000	time 0.6795 (0.9481)	loss 0.8957 (0.8930)	grad_norm 12.8989 (14.7843)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:16 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][20/146]	eta 0:01:37 lr 0.000003	 wd 0.0000	time 0.3617 (0.7770)	loss 0.9902 (0.8878)	grad_norm 24.6499 (14.3053)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:21 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][30/146]	eta 0:01:18 lr 0.000003	 wd 0.0000	time 0.4307 (0.6792)	loss 0.7845 (0.8923)	grad_norm 18.3452 (15.4942)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:28 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][40/146]	eta 0:01:12 lr 0.000003	 wd 0.0000	time 1.1966 (0.6823)	loss 0.8497 (0.8908)	grad_norm 6.8736 (14.6450)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:33 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][50/146]	eta 0:01:02 lr 0.000003	 wd 0.0000	time 0.4157 (0.6519)	loss 0.9896 (0.9046)	grad_norm 15.3517 (14.7986)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:39 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][60/146]	eta 0:00:55 lr 0.000003	 wd 0.0000	time 0.4003 (0.6424)	loss 0.9750 (0.8968)	grad_norm 7.7805 (14.3512)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:44 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][70/146]	eta 0:00:47 lr 0.000003	 wd 0.0000	time 0.4071 (0.6190)	loss 0.8002 (0.9036)	grad_norm 16.3783 (14.4375)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:51 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][80/146]	eta 0:00:41 lr 0.000003	 wd 0.0000	time 2.0126 (0.6278)	loss 0.9700 (0.8962)	grad_norm 10.1317 (14.0325)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:03:56 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][90/146]	eta 0:00:34 lr 0.000003	 wd 0.0000	time 0.4079 (0.6126)	loss 0.9326 (0.9022)	grad_norm 15.1869 (13.8612)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:00 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.4243 (0.5930)	loss 0.8453 (0.9004)	grad_norm 14.5004 (13.7415)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:06 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.3999 (0.5912)	loss 0.6786 (0.8971)	grad_norm 10.2060 (13.7340)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:11 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.5382 (0.5845)	loss 0.9354 (0.8989)	grad_norm 20.2429 (13.9120)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:17 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.6424 (0.5881)	loss 0.8633 (0.9018)	grad_norm 12.5373 (13.9570)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:20 swin_tiny_window14_224] (main.py 234): INFO Train: [6/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2598 (0.5698)	loss 0.7085 (0.9027)	grad_norm 10.3926 (14.0574)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:22 swin_tiny_window14_224] (main.py 243): INFO EPOCH 6 training takes 0:01:21
[2026-01-19 17:04:31 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.301 (9.301)	Loss 0.1324 (0.1324)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:04:34 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.094 (1.140)	Loss 0.3672 (0.3754)	Acc@1 96.875 (88.636)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:04:35 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 85.128 Acc@5 0.000
[2026-01-19 17:04:35 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.1%
[2026-01-19 17:04:35 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 85.64%
[2026-01-19 17:04:41 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][0/146]	eta 0:12:27 lr 0.000003	 wd 0.0000	time 5.1204 (5.1204)	loss 0.7931 (0.7931)	grad_norm 17.9525 (17.9525)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:46 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][10/146]	eta 0:02:09 lr 0.000003	 wd 0.0000	time 0.3490 (0.9495)	loss 0.6452 (0.8217)	grad_norm 8.2177 (14.5166)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:51 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][20/146]	eta 0:01:34 lr 0.000003	 wd 0.0000	time 0.4350 (0.7506)	loss 0.7873 (0.8698)	grad_norm 8.2356 (14.1430)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:04:57 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][30/146]	eta 0:01:20 lr 0.000003	 wd 0.0000	time 0.4089 (0.6981)	loss 0.9588 (0.8636)	grad_norm 9.8312 (13.9447)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:03 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][40/146]	eta 0:01:11 lr 0.000003	 wd 0.0000	time 1.8055 (0.6759)	loss 0.7764 (0.8748)	grad_norm 15.8576 (14.0072)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:08 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][50/146]	eta 0:01:01 lr 0.000003	 wd 0.0000	time 0.6884 (0.6417)	loss 1.0038 (0.8688)	grad_norm 23.1830 (14.3217)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:13 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][60/146]	eta 0:00:53 lr 0.000003	 wd 0.0000	time 0.3809 (0.6227)	loss 0.8610 (0.8646)	grad_norm 17.2068 (14.2390)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:19 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][70/146]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 0.4821 (0.6094)	loss 0.8177 (0.8632)	grad_norm 16.2751 (14.4498)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:25 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 0.4223 (0.6066)	loss 0.9995 (0.8669)	grad_norm 16.6234 (14.4904)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:30 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.3784 (0.5945)	loss 0.7737 (0.8639)	grad_norm 7.6815 (14.0405)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:35 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][100/146]	eta 0:00:26 lr 0.000003	 wd 0.0000	time 0.6309 (0.5865)	loss 0.8406 (0.8649)	grad_norm 11.7784 (14.0475)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:41 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.4294 (0.5890)	loss 0.6949 (0.8698)	grad_norm 10.6621 (14.1323)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:45 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.5167 (0.5788)	loss 0.8101 (0.8656)	grad_norm 9.6827 (13.9149)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:52 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 1.9662 (0.5874)	loss 1.0547 (0.8693)	grad_norm 14.9502 (13.8054)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:56 swin_tiny_window14_224] (main.py 234): INFO Train: [7/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2599 (0.5692)	loss 0.6944 (0.8671)	grad_norm 10.1650 (13.8647)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:05:57 swin_tiny_window14_224] (main.py 243): INFO EPOCH 7 training takes 0:01:21
[2026-01-19 17:06:06 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.322 (9.322)	Loss 0.1147 (0.1147)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:06:09 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.093 (1.109)	Loss 0.3411 (0.3651)	Acc@1 96.875 (88.068)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:06:11 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 83.932 Acc@5 0.000
[2026-01-19 17:06:11 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 83.9%
[2026-01-19 17:06:11 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 85.64%
[2026-01-19 17:06:16 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][0/146]	eta 0:14:08 lr 0.000003	 wd 0.0000	time 5.8117 (5.8117)	loss 1.0651 (1.0651)	grad_norm 12.4817 (12.4817)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:21 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][10/146]	eta 0:02:06 lr 0.000003	 wd 0.0000	time 0.6105 (0.9301)	loss 0.8734 (0.9217)	grad_norm 8.0033 (14.7759)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:25 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][20/146]	eta 0:01:29 lr 0.000003	 wd 0.0000	time 0.6561 (0.7117)	loss 0.7825 (0.9060)	grad_norm 7.8212 (14.7482)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:31 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][30/146]	eta 0:01:17 lr 0.000003	 wd 0.0000	time 0.3950 (0.6702)	loss 0.8890 (0.8753)	grad_norm 12.8611 (13.8436)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:37 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][40/146]	eta 0:01:08 lr 0.000003	 wd 0.0000	time 0.8351 (0.6500)	loss 0.7783 (0.8670)	grad_norm 13.8767 (13.6539)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:43 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][50/146]	eta 0:01:01 lr 0.000003	 wd 0.0000	time 0.3282 (0.6397)	loss 0.7351 (0.8651)	grad_norm 10.0558 (13.5467)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:48 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][60/146]	eta 0:00:52 lr 0.000003	 wd 0.0000	time 0.4435 (0.6158)	loss 0.8421 (0.8669)	grad_norm 13.9181 (13.4536)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:55 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][70/146]	eta 0:00:47 lr 0.000003	 wd 0.0000	time 0.4262 (0.6217)	loss 0.9473 (0.8689)	grad_norm 10.9844 (13.1580)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:06:59 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][80/146]	eta 0:00:39 lr 0.000003	 wd 0.0000	time 0.3577 (0.6026)	loss 0.7022 (0.8663)	grad_norm 12.5829 (13.2831)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:05 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][90/146]	eta 0:00:33 lr 0.000003	 wd 0.0000	time 0.5519 (0.5945)	loss 0.7399 (0.8659)	grad_norm 6.4798 (13.2897)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:11 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 1.3632 (0.5994)	loss 1.0818 (0.8710)	grad_norm 12.4639 (13.0314)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:16 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.3984 (0.5911)	loss 0.9994 (0.8771)	grad_norm 14.7122 (13.3644)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:23 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.3270 (0.5957)	loss 0.8121 (0.8774)	grad_norm 12.7997 (13.1643)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:27 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.4290 (0.5830)	loss 1.0585 (0.8812)	grad_norm 11.3028 (13.1783)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:30 swin_tiny_window14_224] (main.py 234): INFO Train: [8/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2621 (0.5646)	loss 0.8010 (0.8787)	grad_norm 7.1099 (13.0088)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:32 swin_tiny_window14_224] (main.py 243): INFO EPOCH 8 training takes 0:01:21
[2026-01-19 17:07:40 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.537 (8.537)	Loss 0.1175 (0.1175)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:07:44 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.096 (1.088)	Loss 0.3142 (0.3360)	Acc@1 96.875 (89.773)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:07:45 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 85.983 Acc@5 0.000
[2026-01-19 17:07:45 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.0%
[2026-01-19 17:07:45 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_8.pth saving......
[2026-01-19 17:07:46 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_8.pth saved !!!
[2026-01-19 17:07:46 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 8): 85.98% ***
[2026-01-19 17:07:46 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 85.98%
[2026-01-19 17:07:51 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][0/146]	eta 0:10:28 lr 0.000003	 wd 0.0000	time 4.3018 (4.3018)	loss 0.6950 (0.6950)	grad_norm 11.4487 (11.4487)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:07:56 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][10/146]	eta 0:01:57 lr 0.000003	 wd 0.0000	time 0.4806 (0.8604)	loss 0.8590 (0.8023)	grad_norm 8.8542 (11.1156)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:02 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][20/146]	eta 0:01:32 lr 0.000003	 wd 0.0000	time 0.4475 (0.7312)	loss 0.5931 (0.8231)	grad_norm 11.2904 (11.9800)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:06 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][30/146]	eta 0:01:14 lr 0.000003	 wd 0.0000	time 0.4358 (0.6453)	loss 0.7734 (0.8406)	grad_norm 11.3920 (12.6277)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:13 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][40/146]	eta 0:01:07 lr 0.000003	 wd 0.0000	time 0.7241 (0.6406)	loss 0.9187 (0.8522)	grad_norm 19.6895 (12.6623)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:17 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][50/146]	eta 0:00:58 lr 0.000003	 wd 0.0000	time 0.3335 (0.6106)	loss 0.8842 (0.8653)	grad_norm 12.4617 (12.6726)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:23 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][60/146]	eta 0:00:51 lr 0.000003	 wd 0.0000	time 0.7255 (0.5974)	loss 1.0629 (0.8762)	grad_norm 12.9096 (13.2520)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:30 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][70/146]	eta 0:00:46 lr 0.000003	 wd 0.0000	time 1.2624 (0.6114)	loss 1.0049 (0.8780)	grad_norm 10.0685 (13.0274)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:36 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][80/146]	eta 0:00:40 lr 0.000003	 wd 0.0000	time 0.6592 (0.6087)	loss 1.1022 (0.8770)	grad_norm 25.8869 (13.2203)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:42 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][90/146]	eta 0:00:34 lr 0.000003	 wd 0.0000	time 0.4459 (0.6083)	loss 1.0539 (0.8782)	grad_norm 11.6609 (13.1537)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:47 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.4832 (0.5986)	loss 0.8538 (0.8776)	grad_norm 8.9301 (13.0267)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:54 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.8497 (0.6063)	loss 0.8935 (0.8782)	grad_norm 10.6620 (12.9729)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:08:58 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.4743 (0.5942)	loss 0.9002 (0.8776)	grad_norm 6.2850 (12.9111)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:03 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.7464 (0.5876)	loss 0.7372 (0.8781)	grad_norm 8.6286 (12.7410)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:07 swin_tiny_window14_224] (main.py 234): INFO Train: [9/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2627 (0.5760)	loss 0.7639 (0.8735)	grad_norm 13.1576 (12.6426)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:09 swin_tiny_window14_224] (main.py 243): INFO EPOCH 9 training takes 0:01:22
[2026-01-19 17:09:18 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.994 (8.994)	Loss 0.1088 (0.1088)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:09:21 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.092 (1.096)	Loss 0.2896 (0.3167)	Acc@1 96.875 (90.057)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:09:22 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 86.667 Acc@5 0.000
[2026-01-19 17:09:22 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.7%
[2026-01-19 17:09:22 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_9.pth saving......
[2026-01-19 17:09:23 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_9.pth saved !!!
[2026-01-19 17:09:23 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 9): 86.67% ***
[2026-01-19 17:09:23 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:09:28 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][0/146]	eta 0:12:33 lr 0.000003	 wd 0.0000	time 5.1605 (5.1605)	loss 0.8965 (0.8965)	grad_norm 16.3020 (16.3020)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:34 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][10/146]	eta 0:02:16 lr 0.000003	 wd 0.0000	time 0.4375 (1.0048)	loss 0.6850 (0.8682)	grad_norm 23.5144 (16.6030)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:38 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][20/146]	eta 0:01:30 lr 0.000003	 wd 0.0000	time 0.3741 (0.7173)	loss 0.8651 (0.8353)	grad_norm 17.9694 (14.9409)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:45 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][30/146]	eta 0:01:23 lr 0.000003	 wd 0.0000	time 0.4515 (0.7166)	loss 0.6637 (0.8134)	grad_norm 9.3805 (14.3968)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:52 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][40/146]	eta 0:01:14 lr 0.000003	 wd 0.0000	time 1.6026 (0.7000)	loss 0.8758 (0.8213)	grad_norm 12.6998 (14.1402)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:09:58 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][50/146]	eta 0:01:05 lr 0.000003	 wd 0.0000	time 0.3332 (0.6825)	loss 1.1612 (0.8392)	grad_norm 13.9600 (13.8156)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:03 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][60/146]	eta 0:00:55 lr 0.000003	 wd 0.0000	time 0.4293 (0.6474)	loss 0.8003 (0.8491)	grad_norm 6.0551 (13.7262)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:07 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][70/146]	eta 0:00:47 lr 0.000003	 wd 0.0000	time 0.5191 (0.6233)	loss 0.6779 (0.8480)	grad_norm 15.8313 (13.6236)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:14 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][80/146]	eta 0:00:41 lr 0.000003	 wd 0.0000	time 1.4068 (0.6327)	loss 0.7253 (0.8480)	grad_norm 9.6099 (13.5276)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:19 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][90/146]	eta 0:00:34 lr 0.000003	 wd 0.0000	time 0.4403 (0.6159)	loss 0.7584 (0.8452)	grad_norm 8.0130 (13.1754)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:25 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][100/146]	eta 0:00:28 lr 0.000003	 wd 0.0000	time 0.4121 (0.6139)	loss 0.6069 (0.8391)	grad_norm 14.3584 (13.0236)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:30 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.3931 (0.5985)	loss 0.9270 (0.8378)	grad_norm 33.6114 (13.4139)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:37 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 3.1359 (0.6129)	loss 0.7192 (0.8399)	grad_norm 12.8276 (13.5474)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:42 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.4785 (0.6047)	loss 0.9967 (0.8433)	grad_norm 17.5295 (13.5162)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:45 swin_tiny_window14_224] (main.py 234): INFO Train: [10/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2599 (0.5837)	loss 0.9536 (0.8474)	grad_norm 31.4278 (13.6736)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:10:47 swin_tiny_window14_224] (main.py 243): INFO EPOCH 10 training takes 0:01:23
[2026-01-19 17:10:56 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.784 (8.784)	Loss 0.1004 (0.1004)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:10:59 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.118)	Loss 0.2759 (0.3093)	Acc@1 96.875 (89.773)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:11:00 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 86.496 Acc@5 0.000
[2026-01-19 17:11:00 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.5%
[2026-01-19 17:11:00 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:11:07 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][0/146]	eta 0:15:42 lr 0.000003	 wd 0.0000	time 6.4561 (6.4561)	loss 0.8992 (0.8992)	grad_norm 10.1336 (10.1336)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:11 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][10/146]	eta 0:02:16 lr 0.000003	 wd 0.0000	time 0.3906 (1.0022)	loss 0.8097 (0.8684)	grad_norm 7.3576 (12.2074)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:17 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][20/146]	eta 0:01:41 lr 0.000003	 wd 0.0000	time 0.4384 (0.8045)	loss 0.9919 (0.8736)	grad_norm 10.7747 (13.4984)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:23 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][30/146]	eta 0:01:25 lr 0.000003	 wd 0.0000	time 0.4420 (0.7356)	loss 1.0277 (0.8840)	grad_norm 18.4442 (13.4277)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:29 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][40/146]	eta 0:01:15 lr 0.000003	 wd 0.0000	time 0.6449 (0.7115)	loss 0.7645 (0.8661)	grad_norm 11.1614 (12.8740)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:34 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][50/146]	eta 0:01:04 lr 0.000003	 wd 0.0000	time 0.4254 (0.6684)	loss 0.8905 (0.8525)	grad_norm 14.7793 (12.7094)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:40 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][60/146]	eta 0:00:55 lr 0.000003	 wd 0.0000	time 0.3683 (0.6455)	loss 1.0151 (0.8493)	grad_norm 11.9850 (12.4268)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:46 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][70/146]	eta 0:00:48 lr 0.000003	 wd 0.0000	time 0.3386 (0.6410)	loss 0.7831 (0.8482)	grad_norm 13.4859 (12.5502)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:51 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][80/146]	eta 0:00:41 lr 0.000003	 wd 0.0000	time 0.4608 (0.6230)	loss 0.8765 (0.8491)	grad_norm 7.0283 (12.6226)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:11:56 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][90/146]	eta 0:00:34 lr 0.000003	 wd 0.0000	time 0.5563 (0.6161)	loss 0.8505 (0.8541)	grad_norm 18.7378 (12.6752)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:01 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][100/146]	eta 0:00:27 lr 0.000003	 wd 0.0000	time 0.4550 (0.5982)	loss 0.7929 (0.8597)	grad_norm 10.2039 (12.8532)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:06 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][110/146]	eta 0:00:21 lr 0.000003	 wd 0.0000	time 0.3692 (0.5915)	loss 1.2060 (0.8593)	grad_norm 19.7043 (12.8390)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:12 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][120/146]	eta 0:00:15 lr 0.000003	 wd 0.0000	time 0.3867 (0.5924)	loss 0.7953 (0.8584)	grad_norm 18.8207 (12.8246)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:17 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][130/146]	eta 0:00:09 lr 0.000003	 wd 0.0000	time 0.4479 (0.5874)	loss 0.7056 (0.8575)	grad_norm 9.9032 (12.7286)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:22 swin_tiny_window14_224] (main.py 234): INFO Train: [11/30][140/146]	eta 0:00:03 lr 0.000003	 wd 0.0000	time 0.2667 (0.5773)	loss 0.8984 (0.8548)	grad_norm 7.9412 (12.5471)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:23 swin_tiny_window14_224] (main.py 243): INFO EPOCH 11 training takes 0:01:22
[2026-01-19 17:12:31 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.116 (8.116)	Loss 0.0919 (0.0919)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:12:35 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.098 (1.084)	Loss 0.3318 (0.3315)	Acc@1 93.750 (88.636)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:12:36 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 85.470 Acc@5 0.000
[2026-01-19 17:12:36 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.5%
[2026-01-19 17:12:36 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:12:40 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][0/146]	eta 0:10:11 lr 0.000003	 wd 0.0000	time 4.1894 (4.1894)	loss 0.5805 (0.5805)	grad_norm 7.6909 (7.6909)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:47 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][10/146]	eta 0:02:14 lr 0.000003	 wd 0.0000	time 0.6225 (0.9883)	loss 1.0001 (0.8395)	grad_norm 12.5170 (12.0428)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:52 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][20/146]	eta 0:01:37 lr 0.000003	 wd 0.0000	time 0.4782 (0.7746)	loss 0.8910 (0.8375)	grad_norm 8.7806 (11.9382)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:12:57 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][30/146]	eta 0:01:18 lr 0.000003	 wd 0.0000	time 0.3797 (0.6743)	loss 0.7187 (0.8221)	grad_norm 7.6672 (11.7433)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:03 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][40/146]	eta 0:01:10 lr 0.000003	 wd 0.0000	time 0.3689 (0.6618)	loss 0.8606 (0.8381)	grad_norm 8.4349 (13.0173)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:09 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][50/146]	eta 0:01:02 lr 0.000003	 wd 0.0000	time 0.4457 (0.6493)	loss 0.8323 (0.8581)	grad_norm 14.5861 (13.4069)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:15 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][60/146]	eta 0:00:54 lr 0.000002	 wd 0.0000	time 0.4533 (0.6290)	loss 0.9719 (0.8558)	grad_norm 7.1258 (13.2931)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:19 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][70/146]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.5000 (0.6029)	loss 0.8977 (0.8470)	grad_norm 12.3418 (13.0414)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:24 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][80/146]	eta 0:00:38 lr 0.000002	 wd 0.0000	time 0.4174 (0.5869)	loss 0.9459 (0.8511)	grad_norm 7.1498 (12.8081)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:31 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.5122 (0.6012)	loss 0.7321 (0.8431)	grad_norm 12.7514 (12.9434)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:35 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][100/146]	eta 0:00:26 lr 0.000002	 wd 0.0000	time 0.3863 (0.5803)	loss 0.9573 (0.8430)	grad_norm 9.1355 (12.9267)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:41 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.4798 (0.5817)	loss 0.6986 (0.8484)	grad_norm 11.3306 (12.8898)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:47 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 1.8682 (0.5868)	loss 1.2406 (0.8481)	grad_norm 30.8619 (13.2328)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:53 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.6006 (0.5880)	loss 0.7876 (0.8490)	grad_norm 28.3847 (13.2269)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:56 swin_tiny_window14_224] (main.py 234): INFO Train: [12/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2585 (0.5685)	loss 1.1168 (0.8513)	grad_norm 15.5415 (13.2246)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:13:58 swin_tiny_window14_224] (main.py 243): INFO EPOCH 12 training takes 0:01:21
[2026-01-19 17:14:07 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.923 (8.923)	Loss 0.0879 (0.0879)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:14:10 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.092 (1.144)	Loss 0.3188 (0.3259)	Acc@1 96.875 (88.352)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:14:11 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 85.128 Acc@5 0.000
[2026-01-19 17:14:11 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.1%
[2026-01-19 17:14:11 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:14:16 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][0/146]	eta 0:12:30 lr 0.000002	 wd 0.0000	time 5.1396 (5.1396)	loss 0.8963 (0.8963)	grad_norm 12.9125 (12.9125)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:22 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][10/146]	eta 0:02:11 lr 0.000002	 wd 0.0000	time 0.4659 (0.9657)	loss 0.7139 (0.8463)	grad_norm 11.8008 (10.2315)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:27 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][20/146]	eta 0:01:34 lr 0.000002	 wd 0.0000	time 0.4596 (0.7474)	loss 0.9268 (0.8109)	grad_norm 12.0255 (10.4973)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:33 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][30/146]	eta 0:01:22 lr 0.000002	 wd 0.0000	time 0.5105 (0.7122)	loss 0.9256 (0.8167)	grad_norm 8.6705 (12.6572)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:38 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][40/146]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.4118 (0.6540)	loss 0.7859 (0.8169)	grad_norm 10.9845 (12.3690)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:45 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][50/146]	eta 0:01:03 lr 0.000002	 wd 0.0000	time 0.7056 (0.6658)	loss 0.7602 (0.8118)	grad_norm 9.5552 (12.5244)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:50 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][60/146]	eta 0:00:54 lr 0.000002	 wd 0.0000	time 0.3890 (0.6325)	loss 0.8546 (0.8134)	grad_norm 18.9218 (13.4067)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:14:55 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][70/146]	eta 0:00:47 lr 0.000002	 wd 0.0000	time 0.3943 (0.6203)	loss 0.7340 (0.8158)	grad_norm 11.0868 (13.7252)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:01 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][80/146]	eta 0:00:40 lr 0.000002	 wd 0.0000	time 0.4110 (0.6119)	loss 0.6911 (0.8171)	grad_norm 17.1086 (13.5332)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:06 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.3762 (0.6051)	loss 0.8446 (0.8162)	grad_norm 11.0518 (13.6350)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:13 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.3293 (0.6075)	loss 0.8854 (0.8214)	grad_norm 7.4179 (13.3419)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:16 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.3337 (0.5855)	loss 0.8011 (0.8260)	grad_norm 13.5088 (13.3638)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:21 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][120/146]	eta 0:00:14 lr 0.000002	 wd 0.0000	time 0.3864 (0.5745)	loss 0.7715 (0.8276)	grad_norm 8.9920 (13.3003)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:27 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4257 (0.5746)	loss 0.9053 (0.8266)	grad_norm 13.1611 (13.1265)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:30 swin_tiny_window14_224] (main.py 234): INFO Train: [13/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2727 (0.5616)	loss 0.8554 (0.8284)	grad_norm 12.8388 (12.9290)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:32 swin_tiny_window14_224] (main.py 243): INFO EPOCH 13 training takes 0:01:20
[2026-01-19 17:15:41 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.113 (9.113)	Loss 0.0831 (0.0831)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:15:44 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.140)	Loss 0.3145 (0.3243)	Acc@1 93.750 (88.352)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:15:45 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 84.615 Acc@5 0.000
[2026-01-19 17:15:45 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 84.6%
[2026-01-19 17:15:45 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:15:50 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][0/146]	eta 0:12:43 lr 0.000002	 wd 0.0000	time 5.2277 (5.2277)	loss 0.9038 (0.9038)	grad_norm 8.1420 (8.1420)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:15:56 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][10/146]	eta 0:02:07 lr 0.000002	 wd 0.0000	time 0.3922 (0.9400)	loss 0.7455 (0.8511)	grad_norm 10.3151 (10.3669)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:01 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][20/146]	eta 0:01:32 lr 0.000002	 wd 0.0000	time 0.4029 (0.7362)	loss 0.8572 (0.8255)	grad_norm 11.7209 (11.1051)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:07 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][30/146]	eta 0:01:21 lr 0.000002	 wd 0.0000	time 0.4210 (0.6999)	loss 0.8752 (0.8391)	grad_norm 11.9811 (12.2016)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:13 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][40/146]	eta 0:01:11 lr 0.000002	 wd 0.0000	time 1.0108 (0.6730)	loss 0.8691 (0.8341)	grad_norm 12.4214 (12.1264)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:19 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][50/146]	eta 0:01:02 lr 0.000002	 wd 0.0000	time 0.4316 (0.6562)	loss 0.8336 (0.8231)	grad_norm 17.2090 (12.8961)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:23 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][60/146]	eta 0:00:53 lr 0.000002	 wd 0.0000	time 0.4569 (0.6266)	loss 0.8488 (0.8266)	grad_norm 6.9230 (12.8845)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:29 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.6807 (0.6154)	loss 0.9012 (0.8210)	grad_norm 14.3509 (12.6042)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:34 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.3980 (0.6037)	loss 0.8341 (0.8168)	grad_norm 11.9938 (12.6267)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:39 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.4483 (0.5918)	loss 1.0165 (0.8209)	grad_norm 12.5508 (12.3798)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:46 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.3720 (0.5976)	loss 0.8046 (0.8256)	grad_norm 13.8765 (12.8981)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:50 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.4521 (0.5840)	loss 0.9015 (0.8301)	grad_norm 10.2747 (13.0544)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:16:56 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 1.4914 (0.5855)	loss 0.7875 (0.8305)	grad_norm 8.9102 (12.9627)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:17:01 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.3997 (0.5771)	loss 0.7795 (0.8347)	grad_norm 15.0793 (13.0469)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:17:05 swin_tiny_window14_224] (main.py 234): INFO Train: [14/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2607 (0.5664)	loss 0.9513 (0.8344)	grad_norm 6.5808 (12.9115)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:17:07 swin_tiny_window14_224] (main.py 243): INFO EPOCH 14 training takes 0:01:21
[2026-01-19 17:17:16 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.158 (9.158)	Loss 0.0946 (0.0946)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:17:19 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.095 (1.111)	Loss 0.3037 (0.3105)	Acc@1 93.750 (88.920)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:17:20 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 85.641 Acc@5 0.000
[2026-01-19 17:17:20 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 85.6%
[2026-01-19 17:17:20 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:17:25 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][0/146]	eta 0:11:07 lr 0.000002	 wd 0.0000	time 4.5740 (4.5740)	loss 0.8857 (0.8857)	grad_norm 10.8758 (10.8758)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:17:29 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][10/146]	eta 0:01:56 lr 0.000002	 wd 0.0000	time 0.7650 (0.8580)	loss 0.9111 (0.8158)	grad_norm 8.3613 (9.5198)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:17:35 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][20/146]	eta 0:01:32 lr 0.000002	 wd 0.0000	time 0.4083 (0.7322)	loss 0.6519 (0.8359)	grad_norm inf (inf)	loss_scale 8192.0000 (15993.9048)	mem 3825MB
[2026-01-19 17:17:40 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][30/146]	eta 0:01:14 lr 0.000002	 wd 0.0000	time 0.3248 (0.6403)	loss 0.7854 (0.8380)	grad_norm 20.0814 (inf)	loss_scale 8192.0000 (13477.1613)	mem 3825MB
[2026-01-19 17:17:45 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][40/146]	eta 0:01:04 lr 0.000002	 wd 0.0000	time 0.3687 (0.6121)	loss 0.6644 (0.8316)	grad_norm 8.7628 (inf)	loss_scale 8192.0000 (12188.0976)	mem 3825MB
[2026-01-19 17:17:51 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][50/146]	eta 0:00:59 lr 0.000002	 wd 0.0000	time 0.4389 (0.6177)	loss 0.9415 (0.8346)	grad_norm 15.8930 (inf)	loss_scale 8192.0000 (11404.5490)	mem 3825MB
[2026-01-19 17:17:57 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][60/146]	eta 0:00:51 lr 0.000002	 wd 0.0000	time 0.3797 (0.5995)	loss 1.0295 (0.8306)	grad_norm 17.0071 (inf)	loss_scale 8192.0000 (10877.9016)	mem 3825MB
[2026-01-19 17:18:03 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][70/146]	eta 0:00:45 lr 0.000002	 wd 0.0000	time 0.3581 (0.5994)	loss 1.0955 (0.8310)	grad_norm 11.2640 (inf)	loss_scale 8192.0000 (10499.6056)	mem 3825MB
[2026-01-19 17:18:08 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][80/146]	eta 0:00:38 lr 0.000002	 wd 0.0000	time 0.4347 (0.5884)	loss 0.8920 (0.8367)	grad_norm 10.3088 (inf)	loss_scale 8192.0000 (10214.7160)	mem 3825MB
[2026-01-19 17:18:14 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 1.4138 (0.5926)	loss 0.9651 (0.8433)	grad_norm 12.7463 (inf)	loss_scale 8192.0000 (9992.4396)	mem 3825MB
[2026-01-19 17:18:19 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.4583 (0.5876)	loss 1.0891 (0.8402)	grad_norm 16.9030 (inf)	loss_scale 8192.0000 (9814.1782)	mem 3825MB
[2026-01-19 17:18:24 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.4586 (0.5773)	loss 0.8082 (0.8394)	grad_norm 12.0126 (inf)	loss_scale 8192.0000 (9668.0360)	mem 3825MB
[2026-01-19 17:18:30 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.3942 (0.5821)	loss 0.7262 (0.8345)	grad_norm 13.0298 (inf)	loss_scale 8192.0000 (9546.0496)	mem 3825MB
[2026-01-19 17:18:37 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 1.7075 (0.5848)	loss 0.9379 (0.8380)	grad_norm 16.7058 (inf)	loss_scale 8192.0000 (9442.6870)	mem 3825MB
[2026-01-19 17:18:40 swin_tiny_window14_224] (main.py 234): INFO Train: [15/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2588 (0.5678)	loss 0.9806 (0.8395)	grad_norm 17.3775 (inf)	loss_scale 8192.0000 (9353.9858)	mem 3825MB
[2026-01-19 17:18:42 swin_tiny_window14_224] (main.py 243): INFO EPOCH 15 training takes 0:01:21
[2026-01-19 17:18:50 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.510 (8.510)	Loss 0.0821 (0.0821)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:18:54 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.090 (1.138)	Loss 0.2952 (0.3079)	Acc@1 93.750 (89.489)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:18:55 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 86.325 Acc@5 0.000
[2026-01-19 17:18:55 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.3%
[2026-01-19 17:18:55 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 86.67%
[2026-01-19 17:19:00 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][0/146]	eta 0:11:28 lr 0.000002	 wd 0.0000	time 4.7139 (4.7139)	loss 0.7593 (0.7593)	grad_norm 13.0754 (13.0754)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:06 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][10/146]	eta 0:02:16 lr 0.000002	 wd 0.0000	time 0.4072 (1.0027)	loss 1.3237 (0.8364)	grad_norm 25.0506 (12.8939)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:11 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][20/146]	eta 0:01:34 lr 0.000002	 wd 0.0000	time 0.4188 (0.7485)	loss 0.9610 (0.8403)	grad_norm 24.9318 (12.9496)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:16 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][30/146]	eta 0:01:17 lr 0.000002	 wd 0.0000	time 0.6261 (0.6688)	loss 0.7478 (0.8246)	grad_norm 8.6738 (12.4965)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:22 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][40/146]	eta 0:01:09 lr 0.000002	 wd 0.0000	time 0.4315 (0.6585)	loss 0.8992 (0.8305)	grad_norm 7.0674 (12.3324)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:27 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][50/146]	eta 0:01:00 lr 0.000002	 wd 0.0000	time 0.4447 (0.6280)	loss 0.7146 (0.8267)	grad_norm 9.8289 (12.2582)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:34 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][60/146]	eta 0:00:54 lr 0.000002	 wd 0.0000	time 0.3997 (0.6372)	loss 0.7809 (0.8254)	grad_norm 9.6402 (12.3164)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:38 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.4861 (0.6083)	loss 0.8621 (0.8364)	grad_norm 8.6203 (12.4960)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:44 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][80/146]	eta 0:00:40 lr 0.000002	 wd 0.0000	time 0.6788 (0.6102)	loss 0.7337 (0.8346)	grad_norm 16.9015 (12.6384)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:50 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.4178 (0.6044)	loss 0.8286 (0.8308)	grad_norm 8.2801 (12.4407)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:19:57 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][100/146]	eta 0:00:28 lr 0.000002	 wd 0.0000	time 1.9739 (0.6095)	loss 0.6641 (0.8357)	grad_norm 14.7606 (12.3229)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:01 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][110/146]	eta 0:00:21 lr 0.000002	 wd 0.0000	time 0.4907 (0.5973)	loss 0.7653 (0.8376)	grad_norm 8.4015 (12.2381)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:06 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.3860 (0.5853)	loss 0.7011 (0.8427)	grad_norm 9.2758 (12.3784)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:12 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][130/146]	eta 0:00:09 lr 0.000002	 wd 0.0000	time 0.4348 (0.5886)	loss 1.0006 (0.8400)	grad_norm 25.3201 (12.6265)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:16 swin_tiny_window14_224] (main.py 234): INFO Train: [16/30][140/146]	eta 0:00:03 lr 0.000002	 wd 0.0000	time 0.2623 (0.5721)	loss 0.7575 (0.8387)	grad_norm 11.7129 (12.5744)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:17 swin_tiny_window14_224] (main.py 243): INFO EPOCH 16 training takes 0:01:22
[2026-01-19 17:20:26 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.956 (8.956)	Loss 0.0883 (0.0883)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:20:29 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.090 (1.118)	Loss 0.2808 (0.2872)	Acc@1 96.875 (90.909)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:20:30 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.863 Acc@5 0.000
[2026-01-19 17:20:30 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.9%
[2026-01-19 17:20:30 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_16.pth saving......
[2026-01-19 17:20:33 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_16.pth saved !!!
[2026-01-19 17:20:33 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 16): 87.86% ***
[2026-01-19 17:20:33 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 87.86%
[2026-01-19 17:20:38 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][0/146]	eta 0:11:22 lr 0.000002	 wd 0.0000	time 4.6770 (4.6770)	loss 1.0114 (1.0114)	grad_norm 11.6800 (11.6800)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:45 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][10/146]	eta 0:02:25 lr 0.000002	 wd 0.0000	time 1.4277 (1.0709)	loss 0.7070 (0.9105)	grad_norm 13.0567 (14.1259)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:51 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][20/146]	eta 0:01:46 lr 0.000002	 wd 0.0000	time 0.4128 (0.8437)	loss 0.7047 (0.8386)	grad_norm 12.5787 (13.2983)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:20:56 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][30/146]	eta 0:01:25 lr 0.000002	 wd 0.0000	time 0.3966 (0.7395)	loss 0.7635 (0.8306)	grad_norm 7.9125 (12.6075)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:01 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][40/146]	eta 0:01:12 lr 0.000002	 wd 0.0000	time 0.6965 (0.6792)	loss 0.8148 (0.8338)	grad_norm 11.1584 (11.9416)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:06 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][50/146]	eta 0:01:02 lr 0.000002	 wd 0.0000	time 0.7173 (0.6473)	loss 0.7000 (0.8482)	grad_norm 14.6096 (12.0174)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:11 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][60/146]	eta 0:00:52 lr 0.000002	 wd 0.0000	time 0.3646 (0.6149)	loss 0.9514 (0.8467)	grad_norm 8.5802 (11.9672)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:17 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][70/146]	eta 0:00:46 lr 0.000002	 wd 0.0000	time 0.4953 (0.6146)	loss 0.9486 (0.8432)	grad_norm 8.4924 (11.7010)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:21 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][80/146]	eta 0:00:39 lr 0.000002	 wd 0.0000	time 0.4660 (0.5971)	loss 0.8434 (0.8435)	grad_norm 9.0166 (11.5986)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:28 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][90/146]	eta 0:00:33 lr 0.000002	 wd 0.0000	time 0.6847 (0.6061)	loss 0.8942 (0.8450)	grad_norm 21.1744 (11.7829)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:33 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][100/146]	eta 0:00:27 lr 0.000002	 wd 0.0000	time 0.4317 (0.5975)	loss 0.9147 (0.8482)	grad_norm 14.7624 (11.9192)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:38 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][110/146]	eta 0:00:20 lr 0.000002	 wd 0.0000	time 0.4636 (0.5824)	loss 0.7403 (0.8412)	grad_norm 7.4503 (11.8101)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:44 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][120/146]	eta 0:00:15 lr 0.000002	 wd 0.0000	time 0.4262 (0.5836)	loss 0.9222 (0.8424)	grad_norm 7.6439 (11.7015)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:49 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.9850 (0.5793)	loss 0.8121 (0.8420)	grad_norm 14.3241 (11.6609)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:52 swin_tiny_window14_224] (main.py 234): INFO Train: [17/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2631 (0.5608)	loss 0.9415 (0.8448)	grad_norm 9.0604 (11.6865)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:21:54 swin_tiny_window14_224] (main.py 243): INFO EPOCH 17 training takes 0:01:20
[2026-01-19 17:22:01 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 7.804 (7.804)	Loss 0.0807 (0.0807)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:22:05 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.097 (1.068)	Loss 0.3098 (0.3065)	Acc@1 93.750 (89.489)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:22:07 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 86.325 Acc@5 0.000
[2026-01-19 17:22:07 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.3%
[2026-01-19 17:22:07 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 87.86%
[2026-01-19 17:22:12 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][0/146]	eta 0:12:58 lr 0.000001	 wd 0.0000	time 5.3348 (5.3348)	loss 0.7867 (0.7867)	grad_norm 12.1012 (12.1012)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:19 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][10/146]	eta 0:02:34 lr 0.000001	 wd 0.0000	time 0.6022 (1.1383)	loss 0.8928 (0.8587)	grad_norm 10.9062 (11.2853)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:24 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][20/146]	eta 0:01:43 lr 0.000001	 wd 0.0000	time 0.4022 (0.8213)	loss 0.8487 (0.8711)	grad_norm 10.8928 (11.1157)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:29 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][30/146]	eta 0:01:24 lr 0.000001	 wd 0.0000	time 0.4247 (0.7256)	loss 0.8141 (0.8568)	grad_norm 8.3820 (11.3086)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:35 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][40/146]	eta 0:01:14 lr 0.000001	 wd 0.0000	time 0.6092 (0.6992)	loss 0.9962 (0.8588)	grad_norm 17.7396 (11.7422)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:40 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][50/146]	eta 0:01:03 lr 0.000001	 wd 0.0000	time 0.4374 (0.6582)	loss 1.0013 (0.8570)	grad_norm 16.0430 (12.0873)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:46 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][60/146]	eta 0:00:55 lr 0.000001	 wd 0.0000	time 0.4142 (0.6455)	loss 0.9037 (0.8546)	grad_norm 12.5978 (12.0796)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:51 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][70/146]	eta 0:00:47 lr 0.000001	 wd 0.0000	time 0.4119 (0.6194)	loss 0.6492 (0.8530)	grad_norm 6.9798 (12.4924)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:22:57 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 1.5994 (0.6164)	loss 0.7694 (0.8526)	grad_norm 8.2920 (12.0674)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:02 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][90/146]	eta 0:00:34 lr 0.000001	 wd 0.0000	time 0.4531 (0.6095)	loss 0.8481 (0.8535)	grad_norm 9.3510 (11.9179)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:07 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.4032 (0.5991)	loss 0.8347 (0.8500)	grad_norm 11.9013 (11.7819)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:13 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.4172 (0.5989)	loss 0.7313 (0.8411)	grad_norm 10.7922 (11.7895)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:18 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.4473 (0.5876)	loss 0.6811 (0.8369)	grad_norm 8.5290 (12.0094)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:24 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.6798 (0.5893)	loss 0.6672 (0.8300)	grad_norm 13.8465 (12.0062)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:27 swin_tiny_window14_224] (main.py 234): INFO Train: [18/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2628 (0.5714)	loss 0.6114 (0.8287)	grad_norm 7.6918 (11.8053)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:29 swin_tiny_window14_224] (main.py 243): INFO EPOCH 18 training takes 0:01:22
[2026-01-19 17:23:38 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.946 (8.946)	Loss 0.0754 (0.0754)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:23:41 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.114)	Loss 0.2710 (0.2778)	Acc@1 96.875 (92.045)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:23:42 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 88.718 Acc@5 0.000
[2026-01-19 17:23:42 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 88.7%
[2026-01-19 17:23:42 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_18.pth saving......
[2026-01-19 17:23:43 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_18.pth saved !!!
[2026-01-19 17:23:43 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 18): 88.72% ***
[2026-01-19 17:23:43 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 88.72%
[2026-01-19 17:23:47 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][0/146]	eta 0:11:40 lr 0.000001	 wd 0.0000	time 4.7976 (4.7976)	loss 0.7252 (0.7252)	grad_norm 10.4889 (10.4889)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:55 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][10/146]	eta 0:02:26 lr 0.000001	 wd 0.0000	time 0.3973 (1.0788)	loss 0.8554 (0.8001)	grad_norm 14.7365 (15.9112)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:23:59 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][20/146]	eta 0:01:39 lr 0.000001	 wd 0.0000	time 0.4392 (0.7923)	loss 0.7741 (0.7824)	grad_norm 7.6799 (14.5245)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:05 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][30/146]	eta 0:01:24 lr 0.000001	 wd 0.0000	time 0.5166 (0.7292)	loss 0.9458 (0.7892)	grad_norm 9.4737 (13.5806)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:10 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][40/146]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.4917 (0.6642)	loss 0.7838 (0.8135)	grad_norm 10.6268 (14.5400)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:16 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][50/146]	eta 0:01:02 lr 0.000001	 wd 0.0000	time 0.7678 (0.6520)	loss 0.7644 (0.8145)	grad_norm 10.7438 (14.4986)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:21 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][60/146]	eta 0:00:54 lr 0.000001	 wd 0.0000	time 0.4895 (0.6311)	loss 0.6987 (0.8170)	grad_norm 9.7765 (13.8344)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:27 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.4193 (0.6183)	loss 0.8430 (0.8149)	grad_norm 18.1388 (13.8285)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:32 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 0.4494 (0.6121)	loss 0.6869 (0.8141)	grad_norm 6.8580 (13.4990)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:37 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][90/146]	eta 0:00:33 lr 0.000001	 wd 0.0000	time 0.4419 (0.5986)	loss 0.9667 (0.8138)	grad_norm 13.6484 (13.6634)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:44 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.4481 (0.6027)	loss 0.8769 (0.8166)	grad_norm 6.2843 (13.4233)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:48 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.4764 (0.5911)	loss 0.7190 (0.8107)	grad_norm 4.9082 (13.0836)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:52 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][120/146]	eta 0:00:14 lr 0.000001	 wd 0.0000	time 0.4792 (0.5769)	loss 0.9875 (0.8097)	grad_norm 16.5509 (13.0154)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:24:59 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.4082 (0.5854)	loss 0.6959 (0.8098)	grad_norm 17.3821 (12.9535)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:02 swin_tiny_window14_224] (main.py 234): INFO Train: [19/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2746 (0.5649)	loss 0.7907 (0.8070)	grad_norm 32.6657 (12.8999)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:04 swin_tiny_window14_224] (main.py 243): INFO EPOCH 19 training takes 0:01:21
[2026-01-19 17:25:13 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.169 (9.169)	Loss 0.0756 (0.0756)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:25:16 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.090 (1.090)	Loss 0.2632 (0.2651)	Acc@1 96.875 (92.898)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:25:17 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 89.744 Acc@5 0.000
[2026-01-19 17:25:17 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 89.7%
[2026-01-19 17:25:17 swin_tiny_window14_224] (utils.py 146): INFO output/swin_tiny_window14_224/default/ckpt_epoch_19.pth saving......
[2026-01-19 17:25:18 swin_tiny_window14_224] (utils.py 148): INFO output/swin_tiny_window14_224/default/ckpt_epoch_19.pth saved !!!
[2026-01-19 17:25:18 swin_tiny_window14_224] (main.py 177): INFO *** New Best Model Saved (Epoch 19): 89.74% ***
[2026-01-19 17:25:18 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:25:24 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][0/146]	eta 0:14:10 lr 0.000001	 wd 0.0000	time 5.8284 (5.8284)	loss 0.7450 (0.7450)	grad_norm 12.4092 (12.4092)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:29 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][10/146]	eta 0:02:20 lr 0.000001	 wd 0.0000	time 0.3951 (1.0315)	loss 0.8690 (0.8844)	grad_norm 9.0399 (14.2751)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:35 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][20/146]	eta 0:01:43 lr 0.000001	 wd 0.0000	time 0.4861 (0.8225)	loss 0.8546 (0.8910)	grad_norm 11.6396 (12.5929)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:40 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][30/146]	eta 0:01:21 lr 0.000001	 wd 0.0000	time 0.4050 (0.7006)	loss 0.8424 (0.8484)	grad_norm 13.3309 (11.9684)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:45 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 0.5997 (0.6555)	loss 0.9088 (0.8366)	grad_norm 9.7387 (11.8544)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:51 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][50/146]	eta 0:01:02 lr 0.000001	 wd 0.0000	time 0.3046 (0.6523)	loss 0.9282 (0.8450)	grad_norm 14.5866 (11.7692)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:25:56 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][60/146]	eta 0:00:53 lr 0.000001	 wd 0.0000	time 0.4316 (0.6209)	loss 0.6549 (0.8339)	grad_norm 9.7420 (11.3954)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:02 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.4513 (0.6181)	loss 0.8526 (0.8349)	grad_norm 13.4661 (11.4005)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:07 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 0.7802 (0.6066)	loss 0.7543 (0.8310)	grad_norm 13.4846 (11.6237)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:13 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][90/146]	eta 0:00:34 lr 0.000001	 wd 0.0000	time 0.6538 (0.6110)	loss 1.0983 (0.8342)	grad_norm 23.3632 (11.6755)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:18 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.5043 (0.5934)	loss 1.0705 (0.8373)	grad_norm 15.3634 (11.7649)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:23 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.4071 (0.5874)	loss 0.8092 (0.8366)	grad_norm 10.7591 (12.0486)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:30 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.8107 (0.5976)	loss 0.6337 (0.8392)	grad_norm 15.8420 (12.0708)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:34 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.4361 (0.5828)	loss 1.0637 (0.8409)	grad_norm 12.9871 (12.3464)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:37 swin_tiny_window14_224] (main.py 234): INFO Train: [20/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.3892 (0.5651)	loss 0.7670 (0.8379)	grad_norm 8.1493 (12.2800)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:26:39 swin_tiny_window14_224] (main.py 243): INFO EPOCH 20 training takes 0:01:21
[2026-01-19 17:26:47 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 7.634 (7.634)	Loss 0.0735 (0.0735)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:26:51 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.095)	Loss 0.3242 (0.3061)	Acc@1 93.750 (89.773)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:26:52 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 86.667 Acc@5 0.000
[2026-01-19 17:26:52 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 86.7%
[2026-01-19 17:26:52 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:26:57 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][0/146]	eta 0:11:49 lr 0.000001	 wd 0.0000	time 4.8601 (4.8601)	loss 0.8317 (0.8317)	grad_norm 8.1760 (8.1760)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:02 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][10/146]	eta 0:02:01 lr 0.000001	 wd 0.0000	time 0.7544 (0.8956)	loss 0.6480 (0.8195)	grad_norm 8.1442 (9.6995)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:08 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][20/146]	eta 0:01:34 lr 0.000001	 wd 0.0000	time 0.4177 (0.7498)	loss 0.8084 (0.8107)	grad_norm 12.6489 (9.9343)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:13 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][30/146]	eta 0:01:16 lr 0.000001	 wd 0.0000	time 0.3634 (0.6592)	loss 0.7531 (0.8319)	grad_norm 9.4330 (10.2214)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:19 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][40/146]	eta 0:01:09 lr 0.000001	 wd 0.0000	time 1.3319 (0.6568)	loss 0.9440 (0.8177)	grad_norm 8.4382 (10.0765)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:24 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][50/146]	eta 0:01:00 lr 0.000001	 wd 0.0000	time 0.5047 (0.6289)	loss 0.8024 (0.8240)	grad_norm 9.5281 (10.5491)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:29 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][60/146]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.7296 (0.6069)	loss 0.8754 (0.8255)	grad_norm 7.3407 (10.3019)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:35 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][70/146]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 0.4240 (0.5987)	loss 0.6516 (0.8211)	grad_norm 17.1682 (10.7607)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:40 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][80/146]	eta 0:00:38 lr 0.000001	 wd 0.0000	time 0.3432 (0.5839)	loss 1.0221 (0.8166)	grad_norm 21.3557 (11.1133)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:45 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][90/146]	eta 0:00:32 lr 0.000001	 wd 0.0000	time 0.4663 (0.5834)	loss 0.8608 (0.8190)	grad_norm 12.3677 (11.2776)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:51 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][100/146]	eta 0:00:26 lr 0.000001	 wd 0.0000	time 0.4048 (0.5861)	loss 0.7967 (0.8217)	grad_norm 13.9543 (11.2964)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:27:58 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.3594 (0.5900)	loss 1.1751 (0.8227)	grad_norm 17.4970 (11.4226)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:02 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 0.3771 (0.5803)	loss 0.6434 (0.8176)	grad_norm 9.6708 (11.3083)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:07 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.3793 (0.5685)	loss 0.7582 (0.8186)	grad_norm 13.7349 (11.4931)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:12 swin_tiny_window14_224] (main.py 234): INFO Train: [21/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2605 (0.5628)	loss 0.6560 (0.8221)	grad_norm 6.4177 (11.7304)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:13 swin_tiny_window14_224] (main.py 243): INFO EPOCH 21 training takes 0:01:20
[2026-01-19 17:28:22 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.947 (8.947)	Loss 0.0736 (0.0736)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:28:25 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.113)	Loss 0.2939 (0.2851)	Acc@1 93.750 (90.909)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:28:26 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 88.205 Acc@5 0.000
[2026-01-19 17:28:26 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 88.2%
[2026-01-19 17:28:26 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:28:31 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][0/146]	eta 0:10:49 lr 0.000001	 wd 0.0000	time 4.4473 (4.4473)	loss 0.8413 (0.8413)	grad_norm 10.5361 (10.5361)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:37 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][10/146]	eta 0:02:14 lr 0.000001	 wd 0.0000	time 0.4193 (0.9866)	loss 0.7728 (0.8102)	grad_norm 13.2440 (11.5024)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:42 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][20/146]	eta 0:01:33 lr 0.000001	 wd 0.0000	time 0.4376 (0.7388)	loss 0.7655 (0.8293)	grad_norm 8.1420 (11.1763)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:48 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][30/146]	eta 0:01:18 lr 0.000001	 wd 0.0000	time 0.7991 (0.6807)	loss 0.6345 (0.8382)	grad_norm 26.5676 (11.5333)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:28:54 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][40/146]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.8951 (0.6668)	loss 0.6721 (0.8318)	grad_norm 15.2553 (12.5692)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:00 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][50/146]	eta 0:01:03 lr 0.000001	 wd 0.0000	time 0.6113 (0.6631)	loss 1.0748 (0.8406)	grad_norm 14.1392 (12.5164)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:05 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][60/146]	eta 0:00:54 lr 0.000001	 wd 0.0000	time 0.3800 (0.6298)	loss 0.9356 (0.8373)	grad_norm 10.5027 (12.3511)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:10 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][70/146]	eta 0:00:46 lr 0.000001	 wd 0.0000	time 0.4226 (0.6150)	loss 1.0490 (0.8428)	grad_norm 16.9104 (12.5938)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:16 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][80/146]	eta 0:00:40 lr 0.000001	 wd 0.0000	time 1.2042 (0.6147)	loss 1.0581 (0.8435)	grad_norm 16.2707 (12.4522)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:21 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][90/146]	eta 0:00:33 lr 0.000001	 wd 0.0000	time 0.4656 (0.5959)	loss 0.8756 (0.8472)	grad_norm 13.7676 (12.2990)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:26 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][100/146]	eta 0:00:27 lr 0.000001	 wd 0.0000	time 0.5729 (0.5943)	loss 0.6631 (0.8404)	grad_norm 6.2316 (11.9746)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:32 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][110/146]	eta 0:00:21 lr 0.000001	 wd 0.0000	time 0.3574 (0.5891)	loss 0.5550 (0.8380)	grad_norm 15.2699 (11.8902)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:37 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][120/146]	eta 0:00:15 lr 0.000001	 wd 0.0000	time 1.2582 (0.5847)	loss 0.7269 (0.8329)	grad_norm 13.0230 (11.7919)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:43 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][130/146]	eta 0:00:09 lr 0.000001	 wd 0.0000	time 0.4159 (0.5862)	loss 0.8962 (0.8322)	grad_norm 8.6511 (11.7414)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:46 swin_tiny_window14_224] (main.py 234): INFO Train: [22/30][140/146]	eta 0:00:03 lr 0.000001	 wd 0.0000	time 0.2622 (0.5646)	loss 1.0423 (0.8361)	grad_norm 15.3323 (11.8104)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:29:47 swin_tiny_window14_224] (main.py 243): INFO EPOCH 22 training takes 0:01:21
[2026-01-19 17:29:57 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.235 (9.235)	Loss 0.0709 (0.0709)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:30:00 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.092 (1.124)	Loss 0.3140 (0.3027)	Acc@1 93.750 (90.057)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:30:01 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.179 Acc@5 0.000
[2026-01-19 17:30:01 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.2%
[2026-01-19 17:30:01 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:30:05 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][0/146]	eta 0:10:00 lr 0.000001	 wd 0.0000	time 4.1160 (4.1160)	loss 0.7230 (0.7230)	grad_norm 8.8655 (8.8655)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:11 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][10/146]	eta 0:02:04 lr 0.000001	 wd 0.0000	time 0.4196 (0.9155)	loss 0.8340 (0.8050)	grad_norm 8.1146 (10.6044)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:15 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][20/146]	eta 0:01:28 lr 0.000001	 wd 0.0000	time 0.4865 (0.6996)	loss 0.9377 (0.8067)	grad_norm 8.4034 (10.9363)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:22 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][30/146]	eta 0:01:19 lr 0.000001	 wd 0.0000	time 0.4372 (0.6845)	loss 0.7126 (0.8358)	grad_norm 22.6982 (12.9122)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:28 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][40/146]	eta 0:01:10 lr 0.000001	 wd 0.0000	time 0.6439 (0.6624)	loss 0.7598 (0.8388)	grad_norm 14.8563 (13.4249)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:33 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][50/146]	eta 0:01:01 lr 0.000001	 wd 0.0000	time 0.6160 (0.6390)	loss 0.5881 (0.8330)	grad_norm 11.0623 (13.3293)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:38 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][60/146]	eta 0:00:52 lr 0.000001	 wd 0.0000	time 0.4519 (0.6157)	loss 0.9507 (0.8440)	grad_norm 7.9143 (13.3432)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:44 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][70/146]	eta 0:00:45 lr 0.000001	 wd 0.0000	time 1.1484 (0.6041)	loss 0.7506 (0.8384)	grad_norm 9.8878 (12.8553)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:50 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][80/146]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.4082 (0.6034)	loss 0.9164 (0.8295)	grad_norm 11.4741 (12.3497)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:30:55 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.3545 (0.5915)	loss 0.7013 (0.8299)	grad_norm 10.3212 (12.0031)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:01 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.3698 (0.5919)	loss 0.6185 (0.8257)	grad_norm 11.8798 (12.0488)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:05 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][110/146]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 1.0902 (0.5806)	loss 0.7398 (0.8207)	grad_norm 9.7677 (11.9175)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:10 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][120/146]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.5951 (0.5734)	loss 0.8866 (0.8220)	grad_norm 9.7849 (12.0699)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:16 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.3982 (0.5729)	loss 0.7481 (0.8223)	grad_norm 9.1374 (12.2041)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:19 swin_tiny_window14_224] (main.py 234): INFO Train: [23/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2754 (0.5569)	loss 0.5559 (0.8231)	grad_norm 10.0882 (12.2695)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:21 swin_tiny_window14_224] (main.py 243): INFO EPOCH 23 training takes 0:01:19
[2026-01-19 17:31:30 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.412 (9.412)	Loss 0.0695 (0.0695)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:31:33 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.092 (1.134)	Loss 0.3091 (0.2997)	Acc@1 93.750 (90.341)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:31:34 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.350 Acc@5 0.000
[2026-01-19 17:31:34 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.4%
[2026-01-19 17:31:34 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:31:40 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][0/146]	eta 0:13:35 lr 0.000000	 wd 0.0000	time 5.5863 (5.5863)	loss 0.9740 (0.9740)	grad_norm 13.1455 (13.1455)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:44 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][10/146]	eta 0:02:02 lr 0.000000	 wd 0.0000	time 0.7565 (0.9029)	loss 0.7618 (0.8546)	grad_norm 11.0548 (13.6034)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:50 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][20/146]	eta 0:01:34 lr 0.000000	 wd 0.0000	time 0.6715 (0.7475)	loss 0.6651 (0.8297)	grad_norm 13.2989 (12.5068)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:31:56 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][30/146]	eta 0:01:23 lr 0.000000	 wd 0.0000	time 0.4683 (0.7226)	loss 0.8763 (0.8272)	grad_norm 9.5747 (11.9930)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:01 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][40/146]	eta 0:01:09 lr 0.000000	 wd 0.0000	time 0.4474 (0.6521)	loss 1.1037 (0.8206)	grad_norm 16.2583 (11.9613)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:08 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][50/146]	eta 0:01:03 lr 0.000000	 wd 0.0000	time 1.6008 (0.6603)	loss 0.9044 (0.8146)	grad_norm 14.4017 (11.7715)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:13 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][60/146]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 0.4414 (0.6301)	loss 0.9695 (0.8352)	grad_norm 13.2328 (12.3087)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:20 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][70/146]	eta 0:00:48 lr 0.000000	 wd 0.0000	time 0.3251 (0.6401)	loss 0.7939 (0.8284)	grad_norm 9.1301 (12.1080)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:24 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][80/146]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.4015 (0.6122)	loss 0.9470 (0.8327)	grad_norm 12.6493 (11.9697)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:30 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][90/146]	eta 0:00:34 lr 0.000000	 wd 0.0000	time 0.8240 (0.6127)	loss 1.0440 (0.8372)	grad_norm 11.1652 (12.0842)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:35 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.4421 (0.6005)	loss 0.6714 (0.8310)	grad_norm 9.6697 (12.1049)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:40 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.3662 (0.5908)	loss 0.9236 (0.8341)	grad_norm 18.4478 (12.1955)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:46 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.3633 (0.5936)	loss 0.9071 (0.8346)	grad_norm 21.0807 (12.1412)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:51 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.6017 (0.5898)	loss 0.7313 (0.8326)	grad_norm 12.6811 (12.2534)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:54 swin_tiny_window14_224] (main.py 234): INFO Train: [24/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2622 (0.5690)	loss 0.8840 (0.8306)	grad_norm 9.5743 (12.2012)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:32:56 swin_tiny_window14_224] (main.py 243): INFO EPOCH 24 training takes 0:01:21
[2026-01-19 17:33:04 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.228 (8.228)	Loss 0.0706 (0.0706)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:33:08 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.090 (1.072)	Loss 0.3030 (0.2922)	Acc@1 93.750 (90.625)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:33:09 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.692 Acc@5 0.000
[2026-01-19 17:33:09 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.7%
[2026-01-19 17:33:09 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:33:14 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][0/146]	eta 0:13:29 lr 0.000000	 wd 0.0000	time 5.5413 (5.5413)	loss 0.7415 (0.7415)	grad_norm 7.0092 (7.0092)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:20 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][10/146]	eta 0:02:11 lr 0.000000	 wd 0.0000	time 0.5401 (0.9669)	loss 0.9462 (0.8340)	grad_norm 11.4900 (12.6898)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:26 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][20/146]	eta 0:01:41 lr 0.000000	 wd 0.0000	time 0.5301 (0.8070)	loss 0.9130 (0.8744)	grad_norm 10.6907 (13.3590)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:31 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][30/146]	eta 0:01:20 lr 0.000000	 wd 0.0000	time 0.4478 (0.6969)	loss 0.9962 (0.8567)	grad_norm 9.1194 (12.5528)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:37 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][40/146]	eta 0:01:11 lr 0.000000	 wd 0.0000	time 0.4701 (0.6752)	loss 0.7521 (0.8418)	grad_norm 11.2224 (12.2063)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:41 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][50/146]	eta 0:01:00 lr 0.000000	 wd 0.0000	time 0.4659 (0.6299)	loss 0.8559 (0.8423)	grad_norm 6.8653 (12.2785)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:47 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][60/146]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 0.7244 (0.6267)	loss 0.6349 (0.8354)	grad_norm 7.1962 (12.0808)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:52 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][70/146]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.4155 (0.6079)	loss 0.6903 (0.8349)	grad_norm 10.1985 (12.3199)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:33:57 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][80/146]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.3605 (0.5874)	loss 0.8447 (0.8305)	grad_norm 8.0825 (12.1394)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:03 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 1.4263 (0.5937)	loss 0.8612 (0.8363)	grad_norm 10.2022 (12.1991)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:08 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][100/146]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.3981 (0.5848)	loss 0.7042 (0.8352)	grad_norm 9.7697 (12.4506)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:14 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.6514 (0.5837)	loss 0.8631 (0.8344)	grad_norm 9.9765 (12.4232)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:19 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.4058 (0.5815)	loss 0.7593 (0.8333)	grad_norm 16.2601 (12.3207)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:25 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 1.9994 (0.5839)	loss 0.8273 (0.8285)	grad_norm 9.9894 (12.1529)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:29 swin_tiny_window14_224] (main.py 234): INFO Train: [25/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2619 (0.5695)	loss 0.5805 (0.8311)	grad_norm 16.3762 (12.2918)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:31 swin_tiny_window14_224] (main.py 243): INFO EPOCH 25 training takes 0:01:21
[2026-01-19 17:34:39 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.648 (8.648)	Loss 0.0699 (0.0699)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:34:43 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.090 (1.107)	Loss 0.3103 (0.2969)	Acc@1 93.750 (90.341)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:34:44 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.350 Acc@5 0.000
[2026-01-19 17:34:44 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.4%
[2026-01-19 17:34:44 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:34:49 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][0/146]	eta 0:12:08 lr 0.000000	 wd 0.0000	time 4.9931 (4.9931)	loss 1.0713 (1.0713)	grad_norm 15.8683 (15.8683)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:34:55 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][10/146]	eta 0:02:14 lr 0.000000	 wd 0.0000	time 0.4202 (0.9919)	loss 0.7803 (0.8643)	grad_norm 6.1092 (10.9752)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:00 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][20/146]	eta 0:01:35 lr 0.000000	 wd 0.0000	time 0.4536 (0.7549)	loss 1.0361 (0.8325)	grad_norm 10.5707 (14.3014)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:04 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][30/146]	eta 0:01:16 lr 0.000000	 wd 0.0000	time 0.7736 (0.6609)	loss 0.9611 (0.8545)	grad_norm 10.7482 (13.0372)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:10 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][40/146]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 0.3109 (0.6431)	loss 1.0035 (0.8562)	grad_norm 10.5674 (12.7109)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:15 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][50/146]	eta 0:00:59 lr 0.000000	 wd 0.0000	time 0.3971 (0.6205)	loss 0.9594 (0.8461)	grad_norm 13.6854 (12.8112)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:23 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][60/146]	eta 0:00:55 lr 0.000000	 wd 0.0000	time 0.3736 (0.6400)	loss 0.7196 (0.8484)	grad_norm 10.7117 (12.7002)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:27 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][70/146]	eta 0:00:46 lr 0.000000	 wd 0.0000	time 0.5063 (0.6154)	loss 0.7254 (0.8323)	grad_norm 6.5849 (12.2274)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:33 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][80/146]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.4139 (0.6136)	loss 0.5956 (0.8307)	grad_norm 10.5494 (12.4700)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:38 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.3591 (0.5928)	loss 0.6596 (0.8304)	grad_norm 7.8832 (12.5896)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:44 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.7802 (0.5971)	loss 0.7962 (0.8263)	grad_norm 11.6860 (12.3593)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:49 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.3975 (0.5871)	loss 0.7536 (0.8204)	grad_norm 9.3123 (12.4302)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:35:54 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.4186 (0.5801)	loss 0.7629 (0.8231)	grad_norm 7.0052 (12.4333)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:00 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.3894 (0.5802)	loss 0.7884 (0.8222)	grad_norm 6.5287 (12.5207)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:04 swin_tiny_window14_224] (main.py 234): INFO Train: [26/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2599 (0.5677)	loss 0.6841 (0.8238)	grad_norm 11.4467 (12.6198)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:05 swin_tiny_window14_224] (main.py 243): INFO EPOCH 26 training takes 0:01:21
[2026-01-19 17:36:15 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.301 (9.301)	Loss 0.0717 (0.0717)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:36:18 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.091 (1.115)	Loss 0.2971 (0.2864)	Acc@1 93.750 (90.625)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:36:18 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.863 Acc@5 0.000
[2026-01-19 17:36:18 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.9%
[2026-01-19 17:36:18 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:36:25 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][0/146]	eta 0:14:57 lr 0.000000	 wd 0.0000	time 6.1497 (6.1497)	loss 1.0889 (1.0889)	grad_norm 17.3282 (17.3282)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:30 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][10/146]	eta 0:02:21 lr 0.000000	 wd 0.0000	time 0.3801 (1.0401)	loss 1.0382 (0.8538)	grad_norm 14.9111 (14.0612)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:36 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][20/146]	eta 0:01:46 lr 0.000000	 wd 0.0000	time 0.5273 (0.8483)	loss 0.8522 (0.8411)	grad_norm 9.7967 (13.0005)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:41 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][30/146]	eta 0:01:24 lr 0.000000	 wd 0.0000	time 0.3550 (0.7288)	loss 0.8609 (0.8677)	grad_norm 17.3711 (13.0959)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:48 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][40/146]	eta 0:01:15 lr 0.000000	 wd 0.0000	time 2.4659 (0.7169)	loss 0.9379 (0.8682)	grad_norm 16.1264 (13.5634)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:53 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][50/146]	eta 0:01:05 lr 0.000000	 wd 0.0000	time 0.3485 (0.6852)	loss 0.7591 (0.8580)	grad_norm 7.3781 (12.9982)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:36:57 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][60/146]	eta 0:00:54 lr 0.000000	 wd 0.0000	time 0.4455 (0.6380)	loss 0.6634 (0.8511)	grad_norm 14.2092 (12.8812)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:03 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][70/146]	eta 0:00:47 lr 0.000000	 wd 0.0000	time 0.5600 (0.6267)	loss 0.8874 (0.8406)	grad_norm 10.5188 (12.5914)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:08 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][80/146]	eta 0:00:40 lr 0.000000	 wd 0.0000	time 0.9476 (0.6105)	loss 0.9116 (0.8452)	grad_norm 6.2855 (12.3609)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:13 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.3214 (0.5947)	loss 0.9616 (0.8408)	grad_norm 8.0065 (12.0500)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:18 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 0.4370 (0.5909)	loss 0.7909 (0.8420)	grad_norm 8.8627 (12.0999)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:23 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][110/146]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.4612 (0.5808)	loss 1.0158 (0.8520)	grad_norm 8.1581 (12.0746)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:31 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 1.6064 (0.5967)	loss 1.0859 (0.8465)	grad_norm 23.6786 (12.0851)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:35 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.3718 (0.5873)	loss 0.8335 (0.8398)	grad_norm 13.8330 (12.0811)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:39 swin_tiny_window14_224] (main.py 234): INFO Train: [27/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2605 (0.5675)	loss 0.7012 (0.8334)	grad_norm 19.7954 (12.2157)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:37:40 swin_tiny_window14_224] (main.py 243): INFO EPOCH 27 training takes 0:01:21
[2026-01-19 17:37:49 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.443 (8.443)	Loss 0.0707 (0.0707)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:37:52 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.224 (1.069)	Loss 0.3035 (0.2913)	Acc@1 93.750 (90.341)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:37:53 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.521 Acc@5 0.000
[2026-01-19 17:37:53 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.5%
[2026-01-19 17:37:53 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:37:58 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][0/146]	eta 0:12:29 lr 0.000000	 wd 0.0000	time 5.1350 (5.1350)	loss 0.7389 (0.7389)	grad_norm 10.2757 (10.2757)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:03 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][10/146]	eta 0:01:59 lr 0.000000	 wd 0.0000	time 0.3865 (0.8765)	loss 0.7258 (0.8123)	grad_norm 19.8605 (12.3043)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:09 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][20/146]	eta 0:01:32 lr 0.000000	 wd 0.0000	time 0.4130 (0.7344)	loss 0.7350 (0.7984)	grad_norm 6.2237 (11.4451)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:13 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][30/146]	eta 0:01:12 lr 0.000000	 wd 0.0000	time 0.3251 (0.6271)	loss 0.9496 (0.8343)	grad_norm 31.9988 (13.5451)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:19 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][40/146]	eta 0:01:06 lr 0.000000	 wd 0.0000	time 1.0476 (0.6236)	loss 0.9760 (0.8470)	grad_norm 8.3623 (13.0653)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:25 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][50/146]	eta 0:00:58 lr 0.000000	 wd 0.0000	time 0.4274 (0.6120)	loss 0.9214 (0.8433)	grad_norm 15.2222 (13.7066)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:30 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][60/146]	eta 0:00:50 lr 0.000000	 wd 0.0000	time 0.4721 (0.5928)	loss 0.8580 (0.8358)	grad_norm 7.1499 (14.0013)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:36 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][70/146]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.8717 (0.5962)	loss 0.8645 (0.8407)	grad_norm 13.1650 (13.8673)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:41 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][80/146]	eta 0:00:38 lr 0.000000	 wd 0.0000	time 0.4080 (0.5831)	loss 0.7880 (0.8425)	grad_norm 13.2625 (13.6303)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:48 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.4424 (0.5954)	loss 0.9707 (0.8465)	grad_norm 10.0305 (13.6212)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:53 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][100/146]	eta 0:00:27 lr 0.000000	 wd 0.0000	time 1.3923 (0.5914)	loss 1.0302 (0.8486)	grad_norm 17.8958 (13.3358)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:38:59 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][110/146]	eta 0:00:21 lr 0.000000	 wd 0.0000	time 0.5292 (0.5885)	loss 0.9809 (0.8427)	grad_norm 7.7971 (13.3855)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:39:04 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][120/146]	eta 0:00:15 lr 0.000000	 wd 0.0000	time 0.4042 (0.5818)	loss 0.9239 (0.8413)	grad_norm 13.1177 (13.1946)	loss_scale 8192.0000 (8192.0000)	mem 3825MB
[2026-01-19 17:39:09 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.6360 (0.5792)	loss 1.0350 (0.8441)	grad_norm 8.3300 (12.9913)	loss_scale 16384.0000 (8754.8092)	mem 3825MB
[2026-01-19 17:39:14 swin_tiny_window14_224] (main.py 234): INFO Train: [28/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.2606 (0.5694)	loss 0.6388 (0.8385)	grad_norm 11.7651 (12.8654)	loss_scale 16384.0000 (9295.8865)	mem 3825MB
[2026-01-19 17:39:15 swin_tiny_window14_224] (main.py 243): INFO EPOCH 28 training takes 0:01:21
[2026-01-19 17:39:24 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 9.073 (9.073)	Loss 0.0707 (0.0707)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:39:27 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.094 (1.105)	Loss 0.3057 (0.2930)	Acc@1 93.750 (90.341)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:39:28 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.350 Acc@5 0.000
[2026-01-19 17:39:28 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.4%
[2026-01-19 17:39:28 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:39:32 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][0/146]	eta 0:09:45 lr 0.000000	 wd 0.0000	time 4.0100 (4.0100)	loss 0.7053 (0.7053)	grad_norm 15.3492 (15.3492)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:39:38 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][10/146]	eta 0:02:02 lr 0.000000	 wd 0.0000	time 0.5768 (0.9043)	loss 0.7446 (0.8063)	grad_norm 24.1078 (14.0715)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:39:43 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][20/146]	eta 0:01:28 lr 0.000000	 wd 0.0000	time 0.4410 (0.7022)	loss 0.7271 (0.8127)	grad_norm 11.5572 (12.9043)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:39:49 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][30/146]	eta 0:01:17 lr 0.000000	 wd 0.0000	time 0.6808 (0.6665)	loss 0.8974 (0.8022)	grad_norm 11.5539 (12.1246)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:39:55 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][40/146]	eta 0:01:08 lr 0.000000	 wd 0.0000	time 0.4051 (0.6429)	loss 0.7713 (0.7958)	grad_norm 10.2999 (12.0317)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:39:59 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][50/146]	eta 0:00:57 lr 0.000000	 wd 0.0000	time 0.3991 (0.6006)	loss 0.7273 (0.8009)	grad_norm 9.7912 (11.9002)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:06 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][60/146]	eta 0:00:53 lr 0.000000	 wd 0.0000	time 1.4283 (0.6218)	loss 0.8526 (0.8116)	grad_norm 16.2708 (12.3255)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:11 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][70/146]	eta 0:00:45 lr 0.000000	 wd 0.0000	time 0.4298 (0.5956)	loss 0.7499 (0.8061)	grad_norm 13.5403 (12.3078)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:16 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][80/146]	eta 0:00:39 lr 0.000000	 wd 0.0000	time 0.5114 (0.5947)	loss 0.8738 (0.8160)	grad_norm 14.9581 (12.3390)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:22 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][90/146]	eta 0:00:33 lr 0.000000	 wd 0.0000	time 0.4560 (0.5901)	loss 0.7301 (0.8189)	grad_norm 9.0505 (12.0928)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:27 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][100/146]	eta 0:00:26 lr 0.000000	 wd 0.0000	time 0.6772 (0.5793)	loss 0.8560 (0.8200)	grad_norm 12.3374 (12.3926)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:33 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][110/146]	eta 0:00:20 lr 0.000000	 wd 0.0000	time 0.3857 (0.5816)	loss 0.7589 (0.8171)	grad_norm 7.6098 (12.2189)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:37 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][120/146]	eta 0:00:14 lr 0.000000	 wd 0.0000	time 0.3889 (0.5716)	loss 0.9191 (0.8208)	grad_norm 8.8239 (12.1211)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:44 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][130/146]	eta 0:00:09 lr 0.000000	 wd 0.0000	time 0.4254 (0.5759)	loss 1.0714 (0.8218)	grad_norm 15.2136 (12.2488)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:47 swin_tiny_window14_224] (main.py 234): INFO Train: [29/30][140/146]	eta 0:00:03 lr 0.000000	 wd 0.0000	time 0.3022 (0.5616)	loss 0.7194 (0.8237)	grad_norm 13.5027 (12.2306)	loss_scale 16384.0000 (16384.0000)	mem 3825MB
[2026-01-19 17:40:49 swin_tiny_window14_224] (main.py 243): INFO EPOCH 29 training takes 0:01:20
[2026-01-19 17:40:58 swin_tiny_window14_224] (main.py 287): INFO Test: [0/19]	Time 8.991 (8.991)	Loss 0.0707 (0.0707)	Acc@1 100.000 (100.000)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:41:02 swin_tiny_window14_224] (main.py 287): INFO Test: [10/19]	Time 0.090 (1.137)	Loss 0.3054 (0.2928)	Acc@1 93.750 (90.341)	Acc@5 0.000 (0.000)	Mem 3825MB
[2026-01-19 17:41:02 swin_tiny_window14_224] (main.py 294): INFO  * Acc@1 87.350 Acc@5 0.000
[2026-01-19 17:41:02 swin_tiny_window14_224] (main.py 165): INFO Accuracy of the network on the 585 test images: 87.4%
[2026-01-19 17:41:02 swin_tiny_window14_224] (main.py 179): INFO Max accuracy: 89.74%
[2026-01-19 17:41:02 swin_tiny_window14_224] (main.py 183): INFO Training time 0:47:39
